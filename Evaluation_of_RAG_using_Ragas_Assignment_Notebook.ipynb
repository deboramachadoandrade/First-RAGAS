{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating a simple RAG pipeline with [LangChain v0.1.0](https://blog.langchain.dev/langchain-v0-1-0/)\n",
        "  \n",
        "\n",
        "- 🤝 Breakout Room #2:\n",
        "  1. Synthetic Dataset Generation for Evaluation using the [Ragas](https://github.com/explodinggradients/ragas)\n",
        "  2. Evaluating our pipeline with Ragas\n",
        "  3. Making Adjustments to our RAG Pipeline\n",
        "  4. Evaluating our Adjusted pipeline against our baseline\n",
        "  5. Testing OpenAI's Claim\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://blog.langchain.dev/langchain-v0-1-0/) of LangChain v0.1.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "e66cf510-5120-42ed-d0f9-e67e30217a24"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zvAvDNWBpjQ1"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "As well, instead of the remote hosted solution that we used last week (Pinecone), we'll be leveraging Meta's [FAISS](https://github.com/facebookresearch/faiss) as the backend for our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `unstructured` (from [Unstructured-IO](https://github.com/Unstructured-IO/unstructured)) and its dependencies which will allow us to load PDFs using the `UnstructuredPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "ad0b3aa1-071d-4d20-b915-6b4024194b2a"
      },
      "outputs": [],
      "source": [
        "!pip install -qU faiss_cpu pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "4389c3cd-4e2d-455c-cc40-cc6a094b4c42"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.1.0\n",
        "\n",
        "Building on what we learned last week, we'll be leveraging LangChain v0.1.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.1.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCBTrfZSwTHp",
        "outputId": "f720215f-14f5-4053-c7d7-734a0d33c0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DataRepository' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI-Maker-Space/DataRepository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    \"DataRepository/MuskComplaint.pdf\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "5fa7b86c-fe0f-4fb1-d5dd-46f4823e9de4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'DataRepository/MuskComplaint.pdf',\n",
              " 'file_path': 'DataRepository/MuskComplaint.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 46,\n",
              " 'format': 'PDF 1.7',\n",
              " 'title': '',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': '',\n",
              " 'creationDate': '',\n",
              " 'modDate': '',\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "2a9ec4d2-2827-458d-a5f3-a68a84c058a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='ELON MUSK, an individual, \\nPlaintiff, \\nvs. \\nSAMUEL ALTMAN, an individual, GREGORY \\nBROCKMAN, an individual, OPENAI, INC., a \\ncorporation, OPENAI, L.P., a limited \\npartnership, OPENAI, L.L.C., a limited liability \\ncompany, OPENAI GP, L.L.C., a limited \\nliability company, OPENAI OPCO, LLC, a \\nlimited liability company, OPENAI GLOBAL, \\nLLC, a limited liability company, OAI \\nCORPORATION, LLC, a limited liability \\ncompany, OPENAI HOLDINGS, LLC, a limited \\nliability company, and DOES 1 through 100, \\ninclusive, \\nDefendants. \\nCase No.:  \\n[UNLIMITED JURISDICTION] \\n \\nCOMPLAINT FOR (1) BREACH OF \\nCONTRACT, (2) PROMISSORY \\nESTOPPEL, (3) BREACH OF FIDUCIARY \\nDUTY, (4) UNFAIR COMPETITION', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 0, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a FAISS VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "####❓ Question #1:\n",
        "\n",
        "List out a few of the techniques that FAISS uses that make it performant.\n",
        "\n",
        "**Answer** FAISS is very flexible in terms of retrieval options. The default options seem to be Euclidean distance, dot product and cosine similarity (which is essentially a dot product on normalized vectors). However, FAISS also supports alternative retrieval options that offer various levels of compromise between memory, search speed and accuracy. Its GPU implementation significantly accelerates search operations, supporting native multi-GPU configurations. FAISS efficiently handles billions of vectors, crucial for large-scale datasets common in AI applications.\n",
        "\n",
        "> NOTE: Check the [repository](https://github.com/facebookresearch/faiss) for more information about FAISS!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"Who is the plantiff?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "34526432-09f0-4445-93d3-f966f25dd6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='would be owned by the foundation and used ‘for the good of the world’[.]” Plaintiff \\nreplied: “Agree on all.” Ex. 2 at 1.' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 27, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='property and derivative works funded by those monies, Plaintiff is presently unable to ascertain his \\ninterest in or the use, allocation, or distribution of assets without an accounting. Plaintiff is therefore \\nentitled to an accounting.' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 32, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 35 – \\nCOMPLAINT \\n \\nDEMAND FOR JURY TRIAL \\nPlaintiff hereby demands trial by jury as to all issues, claims, and/or causes of action properly \\ntriable before a jury \\n \\nDATED: February 29, 2024 \\nIRELL & MANELLA LLP \\n \\n \\nBy:                                                                 \\nMorgan Chu \\nAlan Heinrich \\nIian Jablon \\nAbigail Sellers \\nJustin Koo \\nHenry White \\n \\nAttorneys for Plaintiff Elon Musk' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 34, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='Exhibit 1' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 35, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eRCq_OKUQbKk"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "fa6d986a-f252-409e-990c-7f2eb077a1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MgAa9JwBuJx"
      },
      "source": [
        "####🏗️ Activity #1:\n",
        "\n",
        "Describe the pipeline shown above in simple terms. You can include a diagram if desired.\n",
        "\n",
        "**Answer**: Above we have a RAG chain that first uses Python's itemgetter to extract the \"question\" from input, passing it to a retriever but also keeping the original \"question\" intact. A RunnablePassthrough then temporarily holds the \"context\" (which is obtained as an output of the \"question\" chained into the retriever) without altering it. Finally, the \"context\" and \"question\" are used as inputs for a prompt for ChatOpenAI, generating a \"response\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "6d926d73-0b0a-40b4-b4b2-48250f97f0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elon Musk\n"
          ]
        }
      ],
      "source": [
        "question = \"Who is the plantiff?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "38418031-7020-4c70-d695-48400e966c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The complaint pertains to breach of fiduciary duty, unfair business practices, and accounting.\n",
            "[Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 31 – \\nCOMPLAINT \\n \\nTHIRD CAUSE OF ACTION \\nBreach of Fiduciary Duty  \\nAgainst All Defendants \\n133. \\nPlaintiff realleges and incorporates by reference only paragraphs of this Complaint \\nnecessary for his claim of Breach of Fiduciary Duty. \\n134. \\nUnder California law, Defendants owe fiduciary duties to Plaintiff, including a duty \\nto use Plaintiff’s contributions for the purposes for which they were made. E.g., Cal. Bus. & Prof. \\nCode § 17510.8. Defendants have repeatedly breached their fiduciary duties to Plaintiff, including \\nby:', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 30, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 33 – \\nCOMPLAINT \\n \\nand by those acting in concert with them arising from these acts of unfair competition and other \\nunfair business practices.  \\n144. \\nPlaintiff is entitled to restitution and/or disgorgement of any and all monies received \\nby Defendants while they engaged in such practices, in addition to prejudgment interest pursuant to \\nBusiness & Professions Code § 17200 et seq. Plaintiff further seeks to enjoin Defendants from \\ncarrying out such activities again in the future, and an order compelling specific performance.   \\nFIFTH CAUSE OF ACTION \\nAccounting', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 32, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 35 – \\nCOMPLAINT \\n \\nDEMAND FOR JURY TRIAL \\nPlaintiff hereby demands trial by jury as to all issues, claims, and/or causes of action properly \\ntriable before a jury \\n \\nDATED: February 29, 2024 \\nIRELL & MANELLA LLP \\n \\n \\nBy:                                                                 \\nMorgan Chu \\nAlan Heinrich \\nIian Jablon \\nAbigail Sellers \\nJustin Koo \\nHenry White \\n \\nAttorneys for Plaintiff Elon Musk', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 34, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='obligations as a remedy for Defendants’ breaches of fiduciary duty. \\nFOURTH CAUSE OF ACTION \\nUnfair Business Practices - Cal. Bus. & Prof. Code §§ 17200 et seq. \\nAgainst All Defendants \\n137. \\nPlaintiff realleges and incorporates by reference only paragraphs of this Complaint \\nnecessary for his claim of Unfair Business Practices. \\n138. \\nCalifornia Business and Professions Code sections 17200 et seq. provides that any \\nperson or entity that engages, has engaged, or proposes to engage in unfair business practices may \\nbe enjoined. \\n139. \\nDefendants have engaged in unfair competition and other unfair business practices', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 31, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''})]\n"
          ]
        }
      ],
      "source": [
        "question = \"What does this complaint pertain to?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# 🤝 Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 1: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evluating on every core metric today, but in order to do that - we'll need to creat a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!\n",
        "\n",
        "> NOTE: This process will use `gpt-3.5-turbo-16k` as the base generator and `gpt-4` as the critic - if you're attempting to create a lot of samples please be aware of cost, as well as rate limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"DataRepository/MuskComplaint.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 400\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "####❓ Question #2:\n",
        "\n",
        "Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "\n",
        "**Answer**:  Because we want to test whether the system can handle unseen data and diverse scenarios effectively, not just the specific conditions it was trained or optimized on. A different strategy might reveal strengths or weaknesses that were not apparent under the training conditions, providing a better understanding of the system's performance and areas for improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "0942c5d1-d151-44af-ad1f-c1373ef3e634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents == eval_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8b4c1aafe67048798cdadd46207b4b84",
            "83e3f8bf55454600b299fe63b608852a",
            "4818628434aa4a0e8d7826f152c0da99",
            "c3e047dfd4ec4a859e0274a54ace1432",
            "1b3b9e3adf85473a81055265d9a5b89f",
            "2a4b2b14a02b46c1ac67fc1581133523",
            "decd5f4c69a845cc8fad4c21524c2fd9",
            "e44a47a5a2184c2780ac27e16ace0f7f",
            "317a7d84efc74420abea8e311137f272",
            "611021c94b8a42c58897925acb8b3c5e",
            "ba72a1f57074488da5e34f8d02e748f8",
            "6de6fb8ef2974573b50bad678620f2d1",
            "09ce5c2f37fb469683ed7cf3bd7566f6",
            "58d7c8b4640249df89b60e9eef4d2328",
            "394fb069eb3c4269bb3c970cc04369a9",
            "2235baa0358a4b8cad60508d5d1d8380",
            "570a1f9809e143ef8d858e1c5dc9837d",
            "42c4905b54d8482588d57485c563ee78",
            "26ee70b94d75449cbe7b7ce40ebc1049",
            "bc3b3593ad1e4c5bad6057a3d3872bb4",
            "c5651973a0534d3da51d0a18b13deff3",
            "8745b8f8f8ec46869c66758c4bc6b2e0"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "b97b381f-ecd0-441d-924d-09e6d2187954"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "675a9f283ae541209c3b3b5135128646",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding nodes:   0%|          | 0/188 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filename and doc_id are the same for all nodes.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e448bc04923847878aceaee530793254",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "\n",
        "generator = TestsetGenerator.with_openai()\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, test_size=12, distributions={simple: 0.25, reasoning: 0.25, multi_context: 0.5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIGT0XLz8ze"
      },
      "source": [
        "####❓ Question #3:\n",
        "\n",
        "`{simple: 0.5, reasoning: 0.25, multi_context: 0.25}`\n",
        "\n",
        "What exactly does this mapping refer to?\n",
        "\n",
        "**Answer** RAGAS provides a synthetic Q&A data genaration module that can cover different levels of complexity. First, 'simple' questions are generated where seeding is used to ensure diversity. Then, the original questions might undergo \"evolutions\", whereby they become more convolved. The new questions might require reasoning in order to be answered ('reasoning' questions), or might require information contained in multiple chunks ('multi_context' questions). This is a way to simulate the variability in queries that production RAG systems might receive. \n",
        "\n",
        "> NOTE: Check out the Ragas documentation on this generation process [here](https://docs.ragas.io/en/stable/concepts/testset_generation.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "a8e95364-f3e4-4f20-da3d-05f6f971afdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='What is the internal design of GPT-4 and has it been released to the public?', contexts=['1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 20 – \\nCOMPLAINT \\n \\nproblems, they show that “[t]he solution given by GPT-4 is correct and the argument is sound, while \\nChatGPT [based on GPT-3] produces an incorrect solution which (in the case of a human) would \\nreflect a lack of understanding of the concept of function inversion.” On another example, they show \\nthat “GPT-4 gives a correct solution while ChatGPT begins by rearranging the terms without any \\nclear direction or purpose, and ends up with an incorrect solution.” \\n89. \\nMicrosoft’s own scientists acknowledge that GPT-4 “attains a form of general \\nintelligence” and that “[g]iven the breadth and depth of GPT-4’s capabilities, we believe that it could \\nreasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence \\n(AGI) system.” \\nG. \\nThe Founding Agreement Is Breached In 2023 \\n90. \\nHaving reached the threshold of AGI, which under the Founding Agreement they \\nwere to develop for the benefit of humanity rather than for any for-profit company or personal profit, \\nDefendants instead radically departed from their mission in breach of the Founding Agreement. \\nGPT-4 is an entirely closed model. The internal design of GPT-4 remains a secret and no code has \\nbeen released. OpenAI has not published a paper describing any aspect of its internal design; it has'], ground_truth='The internal design of GPT-4 is a secret and no code has been released. OpenAI has not published a paper describing any aspect of its internal design.', evolution_type='simple')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "test_df = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "92554c28-97b0-44b5-c356-05367d764ad8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the internal design of GPT-4 and has i...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>The internal design of GPT-4 is a secret and n...</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did OpenAI release in 2019?</td>\n",
              "      <td>[(GPT) along with a detailed paper describing ...</td>\n",
              "      <td>OpenAI released a second-generation model, GPT...</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the impact of the new OpenAI business ...</td>\n",
              "      <td>[new business model, they get the same “for pr...</td>\n",
              "      <td>The new OpenAI business model does not provide...</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What did OpenAI contribute to future models an...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>OpenAI contributed to future models by publish...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How did researchers demonstrate GPT-3's step-b...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When did the defendants breach the Founding Ag...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>The defendants breached the Founding Agreement...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"What is the role of GPT in deep learning and ...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>The role of GPT in deep learning is to pre-tra...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"What was the purpose of the detailed paper re...</td>\n",
              "      <td>[(GPT) along with a detailed paper describing ...</td>\n",
              "      <td>The purpose of the detailed paper released by ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What did OpenAI's release of the GPT-2 model i...</td>\n",
              "      <td>[(GPT) along with a detailed paper describing ...</td>\n",
              "      <td>Their publication proved to be useful to the d...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What did Mr. Musk and Luke Nosek do to stop G...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>Mr. Musk and Luke Nosek attempted to put toget...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What were Bill Joy's concerns about strong AGI...</td>\n",
              "      <td>[the greatest existential threat we face today...</td>\n",
              "      <td>Bill Joy's concerns about strong AGI developme...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are the improvements and performance of G...</td>\n",
              "      <td>[step manner, like a human, “by simply adding ...</td>\n",
              "      <td>GPT-4 is already capable of intelligence that ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the internal design of GPT-4 and has i...   \n",
              "1                    What did OpenAI release in 2019?   \n",
              "2   What is the impact of the new OpenAI business ...   \n",
              "3   What did OpenAI contribute to future models an...   \n",
              "4   How did researchers demonstrate GPT-3's step-b...   \n",
              "5   When did the defendants breach the Founding Ag...   \n",
              "6   \"What is the role of GPT in deep learning and ...   \n",
              "7   \"What was the purpose of the detailed paper re...   \n",
              "8   What did OpenAI's release of the GPT-2 model i...   \n",
              "9   \"What did Mr. Musk and Luke Nosek do to stop G...   \n",
              "10  What were Bill Joy's concerns about strong AGI...   \n",
              "11  What are the improvements and performance of G...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "1   [(GPT) along with a detailed paper describing ...   \n",
              "2   [new business model, they get the same “for pr...   \n",
              "3   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "4   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "5   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "6   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "7   [(GPT) along with a detailed paper describing ...   \n",
              "8   [(GPT) along with a detailed paper describing ...   \n",
              "9   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "10  [the greatest existential threat we face today...   \n",
              "11  [step manner, like a human, “by simply adding ...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   The internal design of GPT-4 is a secret and n...         simple   \n",
              "1   OpenAI released a second-generation model, GPT...         simple   \n",
              "2   The new OpenAI business model does not provide...         simple   \n",
              "3   OpenAI contributed to future models by publish...      reasoning   \n",
              "4   Researchers at the University of Tokyo and Goo...      reasoning   \n",
              "5   The defendants breached the Founding Agreement...      reasoning   \n",
              "6   The role of GPT in deep learning is to pre-tra...  multi_context   \n",
              "7   The purpose of the detailed paper released by ...  multi_context   \n",
              "8   Their publication proved to be useful to the d...  multi_context   \n",
              "9   Mr. Musk and Luke Nosek attempted to put toget...  multi_context   \n",
              "10  Bill Joy's concerns about strong AGI developme...  multi_context   \n",
              "11  GPT-4 is already capable of intelligence that ...  multi_context   \n",
              "\n",
              "    episode_done  \n",
              "0           True  \n",
              "1           True  \n",
              "2           True  \n",
              "3           True  \n",
              "4           True  \n",
              "5           True  \n",
              "6           True  \n",
              "7           True  \n",
              "8           True  \n",
              "9           True  \n",
              "10          True  \n",
              "11          True  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "9e14b904-7d52-4dec-f65e-e6d13c3e9e79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the internal design of GPT-4 and has it been released to the public?',\n",
              " 'answer': 'The internal design of GPT-4 is a complete secret and has not been released to the public.',\n",
              " 'contexts': ['of making its technology and knowledge available to the public. GPT-4’s internal design was kept \\nand remains a complete secret except to OpenAI—and, on information and belief, Microsoft. There \\nare no scientific publications describing the design of GPT-4. Instead, there are just press releases \\nbragging about performance. On information and belief, this secrecy is primarily driven by \\ncommercial considerations, not safety. Although developed by OpenAI using contributions from',\n",
              "  'been released. OpenAI has not published a paper describing any aspect of its internal design; it has \\nsimply issued press releases boasting about its performance. The internal details of GPT-4 are \\nknown only to OpenAI and, on information and belief, to Microsoft. GPT-4 is hence the opposite \\nof “open AI.” And it is closed for propriety commercial reasons: Microsoft stands to make a fortune \\nselling GPT-4 to the public, which would not be possible if OpenAI—as it is required to do—makes \\nthe technology freely available to the public. Contrary to the Founding Agreement, Defendants have \\nchosen to use GPT-4 not for the benefit of humanity, but as proprietary technology to maximize',\n",
              "  'intelligence” and that “[g]iven the breadth and depth of GPT-4’s capabilities, we believe that it could \\nreasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence \\n(AGI) system.” \\nG. \\nThe Founding Agreement Is Breached In 2023 \\n90. \\nHaving reached the threshold of AGI, which under the Founding Agreement they \\nwere to develop for the benefit of humanity rather than for any for-profit company or personal profit, \\nDefendants instead radically departed from their mission in breach of the Founding Agreement. \\nGPT-4 is an entirely closed model. The internal design of GPT-4 remains a secret and no code has',\n",
              "  '1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 8 – \\nCOMPLAINT \\n \\nPlaintiff and others that were intended to benefit the public, GPT-4 is now a de facto Microsoft \\nproprietary algorithm, which it has integrated into its Office software suite.  \\n31. \\nFurthermore, on information and belief, GPT-4 is an AGI algorithm, and hence \\nexpressly outside the scope of Microsoft’s September 2020 exclusive license with OpenAI. In this \\nregard, Microsoft’s own researchers have publicly stated that, “[g]iven the breadth and depth of \\nGPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete)'],\n",
              " 'ground_truth': 'The internal design of GPT-4 is a secret and no code has been released. OpenAI has not published a paper describing any aspect of its internal design.'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 2: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d46db515c4d543d898ef91d05df2d0da",
            "af19ef64986b435c8c118e882e26f6a9",
            "14d8c6593d6b41df8dfb290ab9f55ca1",
            "8531b3d7f1cd424f8d3fc2e6bcd875a0",
            "4e5db0ff4ff44577963dbcc651ea10b8",
            "9caba03e810f4407b78cb1c1b6b9be08",
            "2bf9a43c99cf4e05a0f376fde6af9ca6",
            "384a04784f9745088478d9372161c8ae",
            "c981e401946b4dfca65b18b6ae56bf33",
            "b319ac9b4f1b43d5a41d6f10e6e1c1c6",
            "002fc233bee54ea0a9729365f1e0f972"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "dffb177c-c7c6-421d-9fde-7988f960949e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc93698ef54840029178d793e39f6fde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "71f706b1-b6c6-4eaa-cf75-efe719ed66d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'faithfulness': 0.9750, 'answer_relevancy': 0.7860, 'context_recall': 0.9167, 'context_precision': 0.8773, 'answer_correctness': 0.6623}\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "2acf7822-7029-4c0f-966a-4f7c5d47df1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the internal design of GPT-4 and has i...</td>\n",
              "      <td>The internal design of GPT-4 is a complete sec...</td>\n",
              "      <td>[of making its technology and knowledge availa...</td>\n",
              "      <td>The internal design of GPT-4 is a secret and n...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.536062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did OpenAI release in 2019?</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>[challenging.” At the time, OpenAI stated that...</td>\n",
              "      <td>OpenAI released a second-generation model, GPT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.183429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the impact of the new OpenAI business ...</td>\n",
              "      <td>The impact of the new OpenAI business model is...</td>\n",
              "      <td>[not be the first Court to hold otherwise. \\n1...</td>\n",
              "      <td>The new OpenAI business model does not provide...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.934662</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.744171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What did OpenAI contribute to future models an...</td>\n",
              "      <td>OpenAI contributed to future models by releasi...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>OpenAI contributed to future models by publish...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.925650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.744899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How did researchers demonstrate GPT-3's step-b...</td>\n",
              "      <td>Researchers demonstrated GPT-3's step-by-step ...</td>\n",
              "      <td>[implementation for others to build on. \\n84. ...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.736571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When did the defendants breach the Founding Ag...</td>\n",
              "      <td>The defendants breached the Founding Agreement...</td>\n",
              "      <td>[promises. If specific enforcement is not awar...</td>\n",
              "      <td>The defendants breached the Founding Agreement...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.931720</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"What is the role of GPT in deep learning and ...</td>\n",
              "      <td>GPT plays a significant role in deep learning ...</td>\n",
              "      <td>[those connections to the target language. \\n7...</td>\n",
              "      <td>The role of GPT in deep learning is to pre-tra...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.929960</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"What was the purpose of the detailed paper re...</td>\n",
              "      <td>The purpose of the detailed paper released by ...</td>\n",
              "      <td>[which needed to be trained on a specific task...</td>\n",
              "      <td>The purpose of the detailed paper released by ...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.949323</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.673930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What did OpenAI's release of the GPT-2 model i...</td>\n",
              "      <td>OpenAI's release of the GPT-2 model implied th...</td>\n",
              "      <td>[which needed to be trained on a specific task...</td>\n",
              "      <td>Their publication proved to be useful to the d...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.703378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What did Mr. Musk and Luke Nosek do to stop G...</td>\n",
              "      <td>Mr. Musk and Luke Nosek attempted to put toget...</td>\n",
              "      <td>[capabilities behind closed doors.  \\n38. \\nIn...</td>\n",
              "      <td>Mr. Musk and Luke Nosek attempted to put toget...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.914153</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What were Bill Joy's concerns about strong AGI...</td>\n",
              "      <td>Bill Joy's concerns about strong AGI developme...</td>\n",
              "      <td>[18. \\nMr. Musk has long recognized that AGI p...</td>\n",
              "      <td>Bill Joy's concerns about strong AGI developme...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.970314</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.539162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are the improvements and performance of G...</td>\n",
              "      <td>GPT-4 can solve novel and difficult tasks span...</td>\n",
              "      <td>[titled “Sparks of Artificial General Intellig...</td>\n",
              "      <td>GPT-4 is already capable of intelligence that ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.890587</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.648879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the internal design of GPT-4 and has i...   \n",
              "1                    What did OpenAI release in 2019?   \n",
              "2   What is the impact of the new OpenAI business ...   \n",
              "3   What did OpenAI contribute to future models an...   \n",
              "4   How did researchers demonstrate GPT-3's step-b...   \n",
              "5   When did the defendants breach the Founding Ag...   \n",
              "6   \"What is the role of GPT in deep learning and ...   \n",
              "7   \"What was the purpose of the detailed paper re...   \n",
              "8   What did OpenAI's release of the GPT-2 model i...   \n",
              "9   \"What did Mr. Musk and Luke Nosek do to stop G...   \n",
              "10  What were Bill Joy's concerns about strong AGI...   \n",
              "11  What are the improvements and performance of G...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   The internal design of GPT-4 is a complete sec...   \n",
              "1                                       I don't know.   \n",
              "2   The impact of the new OpenAI business model is...   \n",
              "3   OpenAI contributed to future models by releasi...   \n",
              "4   Researchers demonstrated GPT-3's step-by-step ...   \n",
              "5   The defendants breached the Founding Agreement...   \n",
              "6   GPT plays a significant role in deep learning ...   \n",
              "7   The purpose of the detailed paper released by ...   \n",
              "8   OpenAI's release of the GPT-2 model implied th...   \n",
              "9   Mr. Musk and Luke Nosek attempted to put toget...   \n",
              "10  Bill Joy's concerns about strong AGI developme...   \n",
              "11  GPT-4 can solve novel and difficult tasks span...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [of making its technology and knowledge availa...   \n",
              "1   [challenging.” At the time, OpenAI stated that...   \n",
              "2   [not be the first Court to hold otherwise. \\n1...   \n",
              "3   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "4   [implementation for others to build on. \\n84. ...   \n",
              "5   [promises. If specific enforcement is not awar...   \n",
              "6   [those connections to the target language. \\n7...   \n",
              "7   [which needed to be trained on a specific task...   \n",
              "8   [which needed to be trained on a specific task...   \n",
              "9   [capabilities behind closed doors.  \\n38. \\nIn...   \n",
              "10  [18. \\nMr. Musk has long recognized that AGI p...   \n",
              "11  [titled “Sparks of Artificial General Intellig...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   The internal design of GPT-4 is a secret and n...          1.00   \n",
              "1   OpenAI released a second-generation model, GPT...           NaN   \n",
              "2   The new OpenAI business model does not provide...          1.00   \n",
              "3   OpenAI contributed to future models by publish...          1.00   \n",
              "4   Researchers at the University of Tokyo and Goo...          1.00   \n",
              "5   The defendants breached the Founding Agreement...          1.00   \n",
              "6   The role of GPT in deep learning is to pre-tra...          0.75   \n",
              "7   The purpose of the detailed paper released by ...          1.00   \n",
              "8   Their publication proved to be useful to the d...          1.00   \n",
              "9   Mr. Musk and Luke Nosek attempted to put toget...          1.00   \n",
              "10  Bill Joy's concerns about strong AGI developme...          1.00   \n",
              "11  GPT-4 is already capable of intelligence that ...           NaN   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.000000             1.0           1.000000            0.536062  \n",
              "1           0.000000             0.0           1.000000            0.183429  \n",
              "2           0.934662             1.0           1.000000            0.744171  \n",
              "3           0.925650             1.0           0.805556            0.744899  \n",
              "4           0.999998             1.0           1.000000            0.736571  \n",
              "5           0.931720             1.0           0.333333            1.000000  \n",
              "6           0.929960             1.0           1.000000            0.741102  \n",
              "7           0.949323             1.0           1.000000            0.673930  \n",
              "8           0.985075             1.0           0.583333            0.703378  \n",
              "9           0.914153             1.0           1.000000            0.696000  \n",
              "10          0.970314             1.0           0.805556            0.539162  \n",
              "11          0.890587             1.0           1.000000            0.648879  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfiu_pLh3JL"
      },
      "source": [
        "## Task 3: Making Adjustments to our RAG Pipeline\n",
        "\n",
        "Now that we have established a baseline - we can see how any changes impact our pipeline's performance!\n",
        "\n",
        "Let's modify our retriever and see how that impacts our Ragas metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nKIuM336isBL"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MultiQueryRetriever\n",
        "\n",
        "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rcj3L-i_c8"
      },
      "source": [
        "We'll also re-create our RAG pipeline using the abstractions that come packaged with LangChain v0.1.0!\n",
        "\n",
        "First, let's create a chain to \"stuff\" our documents into our context!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EfdCgTw7jC4i"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYl5WdPnvLu"
      },
      "source": [
        "Next, we'll create the retrieval chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9AK7wHVnn0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cmKORMfMoCjL"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Who is the plantiff?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICMsUWbWoOpf",
        "outputId": "04fb324e-682f-48cc-b369-a78d6396af88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The plaintiff is Elon Musk.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5s8ZGasYoVi6"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"What does this complaint pertain to?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNCdW4hoYT8",
        "outputId": "92d13a09-9e69-48af-fac2-1919123a980c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The complaint pertains to a legal case involving Plaintiff Elon Musk alleging breach of fiduciary duty, unfair business practices, and seeking accounting, restitution, disgorgement of funds, and injunctive relief against all Defendants. The complaint also includes a demand for a jury trial.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxkU0HdpoaiE"
      },
      "source": [
        "Well, just from those responses this chain *feels* better - but lets see how it performs on our eval!\n",
        "\n",
        "Let's do the same process we did before to collect our pipeline's contexts and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kO8cWxn2oinT"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgagfhPUtM2j"
      },
      "source": [
        "Now we can convert this into a dataset, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5FcllGeSovP8"
      },
      "outputs": [],
      "source": [
        "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELYabwktR2C"
      },
      "source": [
        "Let's evaluate on the same metrics we did for the first pipeline and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "50599aa481d8460aa6655330b2b0fae3",
            "cfc93618fc084608bb413667fee91ea8",
            "3e85b387328f4df7b45dccbe6572b9bd",
            "cc50e0150a9947579a919757b85f38c9",
            "c03d5f58d31747d3a344f813755480fc",
            "17fde9c2236b4b1b9990dd2a9fbd58ff",
            "ddbe87e735534504b735211253c4b4d2",
            "2189fea4b75749d7bac330e613c31974",
            "d7148bed10a245509672dc60be6edd47",
            "3367eaf060c845648cda48963481ecb4",
            "4fc8cf791b1344809fe8c7ee9598a20a"
          ]
        },
        "id": "d7uHseWJo2TU",
        "outputId": "a0cf86d6-5b8e-4829-b660-b2c247202811"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dfde0208e5e4cd598341335d94016ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "JsFd0uDd2n5E",
        "outputId": "56ec498b-2100-4b79-db2a-30deb4ffddd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the internal design of GPT-4 and has i...</td>\n",
              "      <td>The internal design of GPT-4 is a complete sec...</td>\n",
              "      <td>[of making its technology and knowledge availa...</td>\n",
              "      <td>The internal design of GPT-4 is a secret and n...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.487739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did OpenAI release in 2019?</td>\n",
              "      <td>In 2019, OpenAI released its Generative Pre-Tr...</td>\n",
              "      <td>[challenging.” At the time, OpenAI stated that...</td>\n",
              "      <td>OpenAI released a second-generation model, GPT...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.866442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.734064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the impact of the new OpenAI business ...</td>\n",
              "      <td>With OpenAI's new business model, investors do...</td>\n",
              "      <td>[not be the first Court to hold otherwise. \\n1...</td>\n",
              "      <td>The new OpenAI business model does not provide...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.895243</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.740703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What did OpenAI contribute to future models an...</td>\n",
              "      <td>OpenAI contributed to future models by releasi...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>OpenAI contributed to future models by publish...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.965545</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.738641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How did researchers demonstrate GPT-3's step-b...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>[implementation for others to build on. \\n84. ...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When did the defendants breach the Founding Ag...</td>\n",
              "      <td>The defendants breached the Founding Agreement...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>The defendants breached the Founding Agreement...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.736943</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.722344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"What is the role of GPT in deep learning and ...</td>\n",
              "      <td>GPT (Generative Pre-Trained Transformer) plays...</td>\n",
              "      <td>[those connections to the target language. \\n7...</td>\n",
              "      <td>The role of GPT in deep learning is to pre-tra...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.919043</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"What was the purpose of the detailed paper re...</td>\n",
              "      <td>The purpose of the detailed paper released by ...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>The purpose of the detailed paper released by ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.949323</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.497426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What did OpenAI's release of the GPT-2 model i...</td>\n",
              "      <td>The release of the GPT-2 model by OpenAI impli...</td>\n",
              "      <td>[which needed to be trained on a specific task...</td>\n",
              "      <td>Their publication proved to be useful to the d...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.966079</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.845957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What did Mr. Musk and Luke Nosek do to stop G...</td>\n",
              "      <td>Mr. Musk and Luke Nosek attempted to put toget...</td>\n",
              "      <td>[capabilities behind closed doors.  \\n38. \\nIn...</td>\n",
              "      <td>Mr. Musk and Luke Nosek attempted to put toget...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.894629</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.675431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What were Bill Joy's concerns about strong AGI...</td>\n",
              "      <td>Bill Joy, the founder of Sun Microsystems, sha...</td>\n",
              "      <td>[18. \\nMr. Musk has long recognized that AGI p...</td>\n",
              "      <td>Bill Joy's concerns about strong AGI developme...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.913358</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.613849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are the improvements and performance of G...</td>\n",
              "      <td>GPT-4 has shown significant improvements and p...</td>\n",
              "      <td>[titled “Sparks of Artificial General Intellig...</td>\n",
              "      <td>GPT-4 is already capable of intelligence that ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.992829</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.540229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is the internal design of GPT-4 and has i...   \n",
              "1                    What did OpenAI release in 2019?   \n",
              "2   What is the impact of the new OpenAI business ...   \n",
              "3   What did OpenAI contribute to future models an...   \n",
              "4   How did researchers demonstrate GPT-3's step-b...   \n",
              "5   When did the defendants breach the Founding Ag...   \n",
              "6   \"What is the role of GPT in deep learning and ...   \n",
              "7   \"What was the purpose of the detailed paper re...   \n",
              "8   What did OpenAI's release of the GPT-2 model i...   \n",
              "9   \"What did Mr. Musk and Luke Nosek do to stop G...   \n",
              "10  What were Bill Joy's concerns about strong AGI...   \n",
              "11  What are the improvements and performance of G...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   The internal design of GPT-4 is a complete sec...   \n",
              "1   In 2019, OpenAI released its Generative Pre-Tr...   \n",
              "2   With OpenAI's new business model, investors do...   \n",
              "3   OpenAI contributed to future models by releasi...   \n",
              "4   Researchers at the University of Tokyo and Goo...   \n",
              "5   The defendants breached the Founding Agreement...   \n",
              "6   GPT (Generative Pre-Trained Transformer) plays...   \n",
              "7   The purpose of the detailed paper released by ...   \n",
              "8   The release of the GPT-2 model by OpenAI impli...   \n",
              "9   Mr. Musk and Luke Nosek attempted to put toget...   \n",
              "10  Bill Joy, the founder of Sun Microsystems, sha...   \n",
              "11  GPT-4 has shown significant improvements and p...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [of making its technology and knowledge availa...   \n",
              "1   [challenging.” At the time, OpenAI stated that...   \n",
              "2   [not be the first Court to hold otherwise. \\n1...   \n",
              "3   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "4   [implementation for others to build on. \\n84. ...   \n",
              "5   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "6   [those connections to the target language. \\n7...   \n",
              "7   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "8   [which needed to be trained on a specific task...   \n",
              "9   [capabilities behind closed doors.  \\n38. \\nIn...   \n",
              "10  [18. \\nMr. Musk has long recognized that AGI p...   \n",
              "11  [titled “Sparks of Artificial General Intellig...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   The internal design of GPT-4 is a secret and n...           1.0   \n",
              "1   OpenAI released a second-generation model, GPT...           0.0   \n",
              "2   The new OpenAI business model does not provide...           1.0   \n",
              "3   OpenAI contributed to future models by publish...           1.0   \n",
              "4   Researchers at the University of Tokyo and Goo...           1.0   \n",
              "5   The defendants breached the Founding Agreement...           1.0   \n",
              "6   The role of GPT in deep learning is to pre-tra...           1.0   \n",
              "7   The purpose of the detailed paper released by ...           1.0   \n",
              "8   Their publication proved to be useful to the d...           1.0   \n",
              "9   Mr. Musk and Luke Nosek attempted to put toget...           1.0   \n",
              "10  Bill Joy's concerns about strong AGI developme...           1.0   \n",
              "11  GPT-4 is already capable of intelligence that ...           1.0   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.000000        1.000000           0.916667            0.487739  \n",
              "1           0.866442        0.000000           1.000000            0.734064  \n",
              "2           0.895243        1.000000           1.000000            0.740703  \n",
              "3           0.965545        1.000000           0.916667            0.738641  \n",
              "4           0.971514        1.000000           1.000000            0.742158  \n",
              "5           0.736943        1.000000           0.250000            0.722344  \n",
              "6           0.919043        1.000000           1.000000            0.803452  \n",
              "7           0.949323        1.000000           1.000000            0.497426  \n",
              "8           0.966079        1.000000           0.638889            0.845957  \n",
              "9           0.894629        0.333333           1.000000            0.675431  \n",
              "10          0.913358        1.000000           0.805556            0.613849  \n",
              "11          0.992829        1.000000           1.000000            0.540229  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results_df = advanced_retrieval_results.to_pandas()\n",
        "advanced_retrieval_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hzqq5VtZ2a"
      },
      "source": [
        "## Task 4: Evaluating our Adjusted Pipeline Against Our Baseline\n",
        "\n",
        "Now we can compare our results and see what directional changes occured!\n",
        "\n",
        "Let's refresh with our initial metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWGRaF5qx3V",
        "outputId": "ee4195d5-f3a3-45df-dff9-5139c93f640f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9750, 'answer_relevancy': 0.7860, 'context_recall': 0.9167, 'context_precision': 0.8773, 'answer_correctness': 0.6623}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFv_yAeotmFs"
      },
      "source": [
        "And see how our advanced retrieval modified our chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpV11dxJo7xa",
        "outputId": "9510b961-4481-40fc-b54e-3a2a8348ce8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9167, 'answer_relevancy': 0.8392, 'context_recall': 0.8611, 'context_precision': 0.8773, 'answer_correctness': 0.6785}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62NYn3iAvTjM",
        "outputId": "2d6eb84d-131c-457c-f71e-881248a4b2b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>-5.833333e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.785953</td>\n",
              "      <td>0.839246</td>\n",
              "      <td>5.329217e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>-5.555556e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>1.689870e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.662299</td>\n",
              "      <td>0.678499</td>\n",
              "      <td>1.620083e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.975000                                    0.916667   \n",
              "1    answer_relevancy  0.785953                                    0.839246   \n",
              "2      context_recall  0.916667                                    0.861111   \n",
              "3   context_precision  0.877315                                    0.877315   \n",
              "4  answer_correctness  0.662299                                    0.678499   \n",
              "\n",
              "          Delta  \n",
              "0 -5.833333e-02  \n",
              "1  5.329217e-02  \n",
              "2 -5.555556e-02  \n",
              "3  1.689870e-12  \n",
              "4  1.620083e-02  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task 5: Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "####🏗️ Activity #2:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "#Let us repeat the process by using \"text-embedding-3-small\" instead of \"text-embedding-ada-002\" as our embedding model:\n",
        "new_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-JPe1_Jx6Rnw"
      },
      "outputs": [],
      "source": [
        "#Again, we store our documents alongside their new embeddings in an index:\n",
        "new_vector_store = FAISS.from_documents(documents, new_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "#And expose our vector_store as a retriever:\n",
        "new_retriever = new_vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "M6Tyc3ZY7Km2"
      },
      "outputs": [],
      "source": [
        "# As we did before with \"text-embedding-ada-002\", we will also consider the effect of an advanced retriever:\n",
        "new_advanced_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "## As we did before with \"text-embedding-ada-002\", we will also consider the effect of document stuffing:\n",
        "new_retrieval_chain = create_retrieval_chain(new_advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: Exception ignored in: <generator object tqdm.__iter__ at 0x7fb35dc71930>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/.local/lib/python3.11/site-packages/tqdm/std.py\", line 1196, in __iter__\n",
            "    self.close()\n",
            "  File \"/home/deboramachadoandrade/.local/lib/python3.11/site-packages/tqdm/notebook.py\", line 279, in close\n",
            "    self.disp(bar_style='danger', check_delay=False)\n",
            "  File \"/home/deboramachadoandrade/.local/lib/python3.11/site-packages/tqdm/notebook.py\", line 178, in display\n",
            "    pbar.bar_style = bar_style\n",
            "    ^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/traitlets/traitlets.py\", line 729, in __set__\n",
            "    self.set(obj, value)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/traitlets/traitlets.py\", line 718, in set\n",
            "    obj._notify_trait(self.name, old_value, new_value)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/traitlets/traitlets.py\", line 1501, in _notify_trait\n",
            "    self.notify_change(\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
            "    self.send_state(key=name)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
            "    self._send(msg, buffers=buffers)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
            "    self.comm.send(data=msg, buffers=buffers)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/comm/base_comm.py\", line 113, in send\n",
            "    self.publish_msg(\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/comm/comm.py\", line 36, in publish_msg\n",
            "    self.kernel.session.send(\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/jupyter_client/session.py\", line 863, in send\n",
            "    stream.send_multipart(to_send, copy=copy)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 330, in send_multipart\n",
            "    return self.io_thread.send_multipart(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 260, in send_multipart\n",
            "    self.schedule(lambda: self._really_send(*args, **kwargs))\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
            "    self._event_pipe.send(b\"\")\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
            "zmq.error.ZMQError: Socket operation on non-socket\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
            "    self.pub_thread.schedule(self._flush)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
            "    self._event_pipe.send(b\"\")\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
            "zmq.error.ZMQError: Socket operation on non-socket\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 648, in write\n",
            "    self._schedule_flush()\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 545, in _schedule_flush\n",
            "    self.pub_thread.schedule(_schedule_in_thread)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
            "    self._event_pipe.send(b\"\")\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
            "zmq.error.ZMQError: Socket operation on non-socket\n",
            "Exception in thread Thread-7:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py\", line 93, in run\n",
            "    results = self.loop.run_until_complete(self._aresults())\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py\", line 81, in _aresults\n",
            "    raise e\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py\", line 76, in _aresults\n",
            "    r = await future\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/asyncio/tasks.py\", line 615, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "           ^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py\", line 36, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py\", line 109, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/metrics/_faithfulness.py\", line 191, in _ascore\n",
            "    p = self._create_nli_prompt(row, statements.get(\"statements\", []))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/metrics/_faithfulness.py\", line 137, in _create_nli_prompt\n",
            "    assert self.llm is not None, \"llm must be set to compute score\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: llm must be set to compute score\n",
            "Exception in threading.excepthook:\n",
            "Exception ignored in thread started by: <bound method Thread._bootstrap of <Runner(Thread-7, stopped 140408612972096)>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/threading.py\", line 1047, in _bootstrap_inner\n",
            "    self._invoke_excepthook(self)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/threading.py\", line 1359, in invoke_excepthook\n",
            "    local_print(\"Exception in threading.excepthook:\",\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
            "    self.pub_thread.schedule(self._flush)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
            "    self._event_pipe.send(b\"\")\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
            "zmq.error.ZMQError: Socket operation on non-socket\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
            "    self.pub_thread.schedule(self._flush)\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
            "    self._event_pipe.send(b\"\")\n",
            "  File \"/home/deboramachadoandrade/anaconda3/envs/llmops-course/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
            "zmq.error.ZMQError: Socket operation on non-socket\n"
          ]
        }
      ],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "86f36527c3df458aae2e54f329c643d7",
            "4aef094bb7764f4fb7917a53de5cb40a",
            "f549d2bd447649c8aac65b0abd25cf23",
            "f413d1bf4faa44edbe5d081b1d3eaff2",
            "db2d3fee6c91439faabbb891a9574392",
            "8f117fd4781949148b1533a38e29c9d6",
            "2ab3fc4aee0b456bb0a06f15de98dafd",
            "9abbc4a5bc11444185ae5ecacbfa102a",
            "f3cf4145eef74579a41f740d62d842c4",
            "21731645603f4144a74f604cf7c01021",
            "c42583faf1f3472b82394432c7623562"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "e918ff10-3631-4563-fdfb-fbab474ea87c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b127f759d874067bb0c930aba1073c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_advanced_retrieval_results = evaluate(new_response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "de1bc7a3-0224-4b8a-95f8-7184fd623661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9394, 'answer_relevancy': 0.8420, 'context_recall': 0.8611, 'context_precision': 0.7737, 'answer_correctness': 0.6618}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>-5.833333e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.785953</td>\n",
              "      <td>0.839246</td>\n",
              "      <td>5.329217e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>-5.555556e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>1.689870e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.662299</td>\n",
              "      <td>0.678499</td>\n",
              "      <td>1.620083e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.975000                                    0.916667   \n",
              "1    answer_relevancy  0.785953                                    0.839246   \n",
              "2      context_recall  0.916667                                    0.861111   \n",
              "3   context_precision  0.877315                                    0.877315   \n",
              "4  answer_correctness  0.662299                                    0.678499   \n",
              "\n",
              "          Delta  \n",
              "0 -5.833333e-02  \n",
              "1  5.329217e-02  \n",
              "2 -5.555556e-02  \n",
              "3  1.689870e-12  \n",
              "4  1.620083e-02  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "9e89e7f1-13e9-436d-e80a-c5241e1b945a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>ADA</th>\n",
              "      <th>Text Embedding 3</th>\n",
              "      <th>Delta - TE3 -&gt; ADA</th>\n",
              "      <th>Delta - TE3 -&gt; Baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>-0.035606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.785953</td>\n",
              "      <td>0.839246</td>\n",
              "      <td>0.841989</td>\n",
              "      <td>0.002743</td>\n",
              "      <td>0.056035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>0.877315</td>\n",
              "      <td>0.773727</td>\n",
              "      <td>-0.103588</td>\n",
              "      <td>-0.103588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.662299</td>\n",
              "      <td>0.678499</td>\n",
              "      <td>0.661827</td>\n",
              "      <td>-0.016673</td>\n",
              "      <td>-0.000472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline       ADA  Text Embedding 3  \\\n",
              "0        faithfulness  0.975000  0.916667          0.939394   \n",
              "1    answer_relevancy  0.785953  0.839246          0.841989   \n",
              "2      context_recall  0.916667  0.861111          0.861111   \n",
              "3   context_precision  0.877315  0.877315          0.773727   \n",
              "4  answer_correctness  0.662299  0.678499          0.661827   \n",
              "\n",
              "   Delta - TE3 -> ADA  Delta - TE3 -> Baseline  \n",
              "0            0.022727                -0.035606  \n",
              "1            0.002743                 0.056035  \n",
              "2            0.000000                -0.055556  \n",
              "3           -0.103588                -0.103588  \n",
              "4           -0.016673                -0.000472  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_original = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(new_advanced_retrieval_results.items()), columns=['Metric', 'Text Embedding 3'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['Delta - TE3 -> ADA'] = df_merged['Text Embedding 3'] - df_merged['ADA']\n",
        "df_merged['Delta - TE3 -> Baseline'] = df_merged['Text Embedding 3'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "####❓ Question #4:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?\n",
        "\n",
        "**Answer** Based on the results we obtained, `text-embedding-3-small` does not appear to be significantly better than `ada`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOciJLABDBnA"
      },
      "source": [
        "## BONUS ACTIVITY: Showcase Multi-Context Perfomance Changes\n",
        "\n",
        "Now that we've looked at a number of different examples - showcase the difference on the multi-context *specific* questions that were synthetically generated.\n",
        "\n",
        "> NOTE: You have all the data you'll need already in the notebook if you made it to this step!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MY8l2EksDH43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b55d1a71a4f245abaef6fa758fe83472",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 1.0000, 'answer_relevancy': 0.9325, 'context_recall': 1.0000, 'context_precision': 0.9074, 'answer_correctness': 0.6698}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The quick way to do that would be realising that the 'multi_context' questions in our dataset correspond to rows 6 to 11, by inspecting test_df. \n",
        "# However, a rigorous solution would be methodically filtering the rows of test_df that have ['evolution_type']== 'multi_context':\n",
        "multi_test_df = test_df[test_df['evolution_type']== 'multi_context'] \n",
        "\n",
        "#Then proceeding with all the steps with this filtered data frame:\n",
        "multi_test_questions = multi_test_df[\"question\"].values.tolist()\n",
        "multi_test_groundtruths = multi_test_df[\"ground_truth\"].values.tolist()\n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "#We invoke our RAG pipeline to get answers and contexts:\n",
        "for question in multi_test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "multi_response_dataset = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "#Finally we get results for the metrics when only multi-context questions were used in the evaluation:\n",
        "multi_results = evaluate(multi_response_dataset, metrics)\n",
        "\n",
        "multi_results\n",
        "                                        \n",
        "                                        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: "
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2aafec23e5ad4dccbb8aa37de2d28697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 1.0000, 'answer_relevancy': 0.9304, 'context_recall': 0.8889, 'context_precision': 0.8965, 'answer_correctness': 0.7835}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We do the same procedure for the modified RAG with advanced retrieval and document stuffing: \n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in multi_test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "multi_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "\n",
        "multi_advanced_retrieval_results = evaluate(multi_response_dataset_advanced_retrieval, metrics)\n",
        "multi_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Finally we repeat the procedure considering the change of embeddings model from ADA to 3-small:\n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in multi_test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b31998e8acdf4adb81f692ec99a6d62c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 1.0000, 'answer_relevancy': 0.9320, 'context_recall': 0.8889, 'context_precision': 0.8898, 'answer_correctness': 0.6969}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "multi_new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "\n",
        "multi_new_advanced_retrieval_results = evaluate(multi_new_response_dataset_advanced_retrieval, metrics)\n",
        "multi_new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>ADA</th>\n",
              "      <th>Text Embedding 3</th>\n",
              "      <th>Delta - TE3 -&gt; ADA</th>\n",
              "      <th>Delta - TE3 -&gt; Baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.932505</td>\n",
              "      <td>0.930434</td>\n",
              "      <td>0.932018</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>-0.000487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.907407</td>\n",
              "      <td>0.896528</td>\n",
              "      <td>0.889815</td>\n",
              "      <td>-0.006713</td>\n",
              "      <td>-0.017593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.669838</td>\n",
              "      <td>0.783547</td>\n",
              "      <td>0.696919</td>\n",
              "      <td>-0.086629</td>\n",
              "      <td>0.027081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline       ADA  Text Embedding 3  \\\n",
              "0        faithfulness  1.000000  1.000000          1.000000   \n",
              "1    answer_relevancy  0.932505  0.930434          0.932018   \n",
              "2      context_recall  1.000000  0.888889          0.888889   \n",
              "3   context_precision  0.907407  0.896528          0.889815   \n",
              "4  answer_correctness  0.669838  0.783547          0.696919   \n",
              "\n",
              "   Delta - TE3 -> ADA  Delta - TE3 -> Baseline  \n",
              "0            0.000000                 0.000000  \n",
              "1            0.001584                -0.000487  \n",
              "2            0.000000                -0.111111  \n",
              "3           -0.006713                -0.017593  \n",
              "4           -0.086629                 0.027081  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now all that is left is to build a table for comparison:\n",
        "\n",
        "df_baseline = pd.DataFrame(list(multi_results.items()), columns=['Metric', 'Baseline'])\n",
        "df_original = pd.DataFrame(list(multi_advanced_retrieval_results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(multi_new_advanced_retrieval_results.items()), columns=['Metric', 'Text Embedding 3'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['Delta - TE3 -> ADA'] = df_merged['Text Embedding 3'] - df_merged['ADA']\n",
        "df_merged['Delta - TE3 -> Baseline'] = df_merged['Text Embedding 3'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we got similar results by using only multi-context questions for evaluation as opposed to using simple, reasoning and multi-context questions (i.e. both embedding models seem to be roughly equivalent in terms for the metrics used), at least for this specific use case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002fc233bee54ea0a9729365f1e0f972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09ce5c2f37fb469683ed7cf3bd7566f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570a1f9809e143ef8d858e1c5dc9837d",
            "placeholder": "​",
            "style": "IPY_MODEL_42c4905b54d8482588d57485c563ee78",
            "value": "Generating: 100%"
          }
        },
        "14d8c6593d6b41df8dfb290ab9f55ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_384a04784f9745088478d9372161c8ae",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c981e401946b4dfca65b18b6ae56bf33",
            "value": 50
          }
        },
        "17fde9c2236b4b1b9990dd2a9fbd58ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3b9e3adf85473a81055265d9a5b89f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "21731645603f4144a74f604cf7c01021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2189fea4b75749d7bac330e613c31974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2235baa0358a4b8cad60508d5d1d8380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ee70b94d75449cbe7b7ce40ebc1049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4b2b14a02b46c1ac67fc1581133523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab3fc4aee0b456bb0a06f15de98dafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf9a43c99cf4e05a0f376fde6af9ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317a7d84efc74420abea8e311137f272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3367eaf060c845648cda48963481ecb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384a04784f9745088478d9372161c8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394fb069eb3c4269bb3c970cc04369a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5651973a0534d3da51d0a18b13deff3",
            "placeholder": "​",
            "style": "IPY_MODEL_8745b8f8f8ec46869c66758c4bc6b2e0",
            "value": " 10/10 [00:40&lt;00:00,  6.80s/it]"
          }
        },
        "3e85b387328f4df7b45dccbe6572b9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2189fea4b75749d7bac330e613c31974",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7148bed10a245509672dc60be6edd47",
            "value": 50
          }
        },
        "42c4905b54d8482588d57485c563ee78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4818628434aa4a0e8d7826f152c0da99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44a47a5a2184c2780ac27e16ace0f7f",
            "max": 318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_317a7d84efc74420abea8e311137f272",
            "value": 318
          }
        },
        "4aef094bb7764f4fb7917a53de5cb40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f117fd4781949148b1533a38e29c9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab3fc4aee0b456bb0a06f15de98dafd",
            "value": "Evaluating: 100%"
          }
        },
        "4e5db0ff4ff44577963dbcc651ea10b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc8cf791b1344809fe8c7ee9598a20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50599aa481d8460aa6655330b2b0fae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfc93618fc084608bb413667fee91ea8",
              "IPY_MODEL_3e85b387328f4df7b45dccbe6572b9bd",
              "IPY_MODEL_cc50e0150a9947579a919757b85f38c9"
            ],
            "layout": "IPY_MODEL_c03d5f58d31747d3a344f813755480fc"
          }
        },
        "570a1f9809e143ef8d858e1c5dc9837d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d7c8b4640249df89b60e9eef4d2328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ee70b94d75449cbe7b7ce40ebc1049",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc3b3593ad1e4c5bad6057a3d3872bb4",
            "value": 10
          }
        },
        "611021c94b8a42c58897925acb8b3c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de6fb8ef2974573b50bad678620f2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09ce5c2f37fb469683ed7cf3bd7566f6",
              "IPY_MODEL_58d7c8b4640249df89b60e9eef4d2328",
              "IPY_MODEL_394fb069eb3c4269bb3c970cc04369a9"
            ],
            "layout": "IPY_MODEL_2235baa0358a4b8cad60508d5d1d8380"
          }
        },
        "83e3f8bf55454600b299fe63b608852a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a4b2b14a02b46c1ac67fc1581133523",
            "placeholder": "​",
            "style": "IPY_MODEL_decd5f4c69a845cc8fad4c21524c2fd9",
            "value": "embedding nodes: 100%"
          }
        },
        "8531b3d7f1cd424f8d3fc2e6bcd875a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b319ac9b4f1b43d5a41d6f10e6e1c1c6",
            "placeholder": "​",
            "style": "IPY_MODEL_002fc233bee54ea0a9729365f1e0f972",
            "value": " 50/50 [00:21&lt;00:00,  1.43it/s]"
          }
        },
        "86f36527c3df458aae2e54f329c643d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aef094bb7764f4fb7917a53de5cb40a",
              "IPY_MODEL_f549d2bd447649c8aac65b0abd25cf23",
              "IPY_MODEL_f413d1bf4faa44edbe5d081b1d3eaff2"
            ],
            "layout": "IPY_MODEL_db2d3fee6c91439faabbb891a9574392"
          }
        },
        "8745b8f8f8ec46869c66758c4bc6b2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4c1aafe67048798cdadd46207b4b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83e3f8bf55454600b299fe63b608852a",
              "IPY_MODEL_4818628434aa4a0e8d7826f152c0da99",
              "IPY_MODEL_c3e047dfd4ec4a859e0274a54ace1432"
            ],
            "layout": "IPY_MODEL_1b3b9e3adf85473a81055265d9a5b89f"
          }
        },
        "8f117fd4781949148b1533a38e29c9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9abbc4a5bc11444185ae5ecacbfa102a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9caba03e810f4407b78cb1c1b6b9be08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af19ef64986b435c8c118e882e26f6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9caba03e810f4407b78cb1c1b6b9be08",
            "placeholder": "​",
            "style": "IPY_MODEL_2bf9a43c99cf4e05a0f376fde6af9ca6",
            "value": "Evaluating: 100%"
          }
        },
        "b319ac9b4f1b43d5a41d6f10e6e1c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba72a1f57074488da5e34f8d02e748f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3b3593ad1e4c5bad6057a3d3872bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c03d5f58d31747d3a344f813755480fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e047dfd4ec4a859e0274a54ace1432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611021c94b8a42c58897925acb8b3c5e",
            "placeholder": "​",
            "style": "IPY_MODEL_ba72a1f57074488da5e34f8d02e748f8",
            "value": " 318/318 [00:30&lt;00:00,  1.69s/it]"
          }
        },
        "c42583faf1f3472b82394432c7623562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5651973a0534d3da51d0a18b13deff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c981e401946b4dfca65b18b6ae56bf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc50e0150a9947579a919757b85f38c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3367eaf060c845648cda48963481ecb4",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc8cf791b1344809fe8c7ee9598a20a",
            "value": " 50/50 [00:27&lt;00:00,  2.66it/s]"
          }
        },
        "cfc93618fc084608bb413667fee91ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fde9c2236b4b1b9990dd2a9fbd58ff",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbe87e735534504b735211253c4b4d2",
            "value": "Evaluating: 100%"
          }
        },
        "d46db515c4d543d898ef91d05df2d0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af19ef64986b435c8c118e882e26f6a9",
              "IPY_MODEL_14d8c6593d6b41df8dfb290ab9f55ca1",
              "IPY_MODEL_8531b3d7f1cd424f8d3fc2e6bcd875a0"
            ],
            "layout": "IPY_MODEL_4e5db0ff4ff44577963dbcc651ea10b8"
          }
        },
        "d7148bed10a245509672dc60be6edd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db2d3fee6c91439faabbb891a9574392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbe87e735534504b735211253c4b4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "decd5f4c69a845cc8fad4c21524c2fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e44a47a5a2184c2780ac27e16ace0f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3cf4145eef74579a41f740d62d842c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f413d1bf4faa44edbe5d081b1d3eaff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21731645603f4144a74f604cf7c01021",
            "placeholder": "​",
            "style": "IPY_MODEL_c42583faf1f3472b82394432c7623562",
            "value": " 50/50 [00:22&lt;00:00,  1.83it/s]"
          }
        },
        "f549d2bd447649c8aac65b0abd25cf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abbc4a5bc11444185ae5ecacbfa102a",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3cf4145eef74579a41f740d62d842c4",
            "value": 50
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
