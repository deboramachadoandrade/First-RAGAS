{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating a simple RAG pipeline with [LangChain v0.1.0](https://blog.langchain.dev/langchain-v0-1-0/)\n",
        "  \n",
        "\n",
        "- 🤝 Breakout Room #2:\n",
        "  1. Synthetic Dataset Generation for Evaluation using the [Ragas](https://github.com/explodinggradients/ragas)\n",
        "  2. Evaluating our pipeline with Ragas\n",
        "  3. Making Adjustments to our RAG Pipeline\n",
        "  4. Evaluating our Adjusted pipeline against our baseline\n",
        "  5. Testing OpenAI's Claim\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://blog.langchain.dev/langchain-v0-1-0/) of LangChain v0.1.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "e66cf510-5120-42ed-d0f9-e67e30217a24"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "zvAvDNWBpjQ1"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "As well, instead of the remote hosted solution that we used last week (Pinecone), we'll be leveraging Meta's [FAISS](https://github.com/facebookresearch/faiss) as the backend for our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `unstructured` (from [Unstructured-IO](https://github.com/Unstructured-IO/unstructured)) and its dependencies which will allow us to load PDFs using the `UnstructuredPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "ad0b3aa1-071d-4d20-b915-6b4024194b2a"
      },
      "outputs": [],
      "source": [
        "!pip install -qU faiss_cpu pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "4389c3cd-4e2d-455c-cc40-cc6a094b4c42"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.1.0\n",
        "\n",
        "Building on what we learned last week, we'll be leveraging LangChain v0.1.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.1.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCBTrfZSwTHp",
        "outputId": "f720215f-14f5-4053-c7d7-734a0d33c0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DataRepository' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI-Maker-Space/DataRepository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    \"DataRepository/MuskComplaint.pdf\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "5fa7b86c-fe0f-4fb1-d5dd-46f4823e9de4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'DataRepository/MuskComplaint.pdf',\n",
              " 'file_path': 'DataRepository/MuskComplaint.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 46,\n",
              " 'format': 'PDF 1.7',\n",
              " 'title': '',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': '',\n",
              " 'creationDate': '',\n",
              " 'modDate': '',\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 368,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "2a9ec4d2-2827-458d-a5f3-a68a84c058a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "execution_count": 370,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='ELON MUSK, an individual, \\nPlaintiff, \\nvs. \\nSAMUEL ALTMAN, an individual, GREGORY \\nBROCKMAN, an individual, OPENAI, INC., a \\ncorporation, OPENAI, L.P., a limited \\npartnership, OPENAI, L.L.C., a limited liability \\ncompany, OPENAI GP, L.L.C., a limited \\nliability company, OPENAI OPCO, LLC, a \\nlimited liability company, OPENAI GLOBAL, \\nLLC, a limited liability company, OAI \\nCORPORATION, LLC, a limited liability \\ncompany, OPENAI HOLDINGS, LLC, a limited \\nliability company, and DOES 1 through 100, \\ninclusive, \\nDefendants. \\nCase No.:  \\n[UNLIMITED JURISDICTION] \\n \\nCOMPLAINT FOR (1) BREACH OF \\nCONTRACT, (2) PROMISSORY \\nESTOPPEL, (3) BREACH OF FIDUCIARY \\nDUTY, (4) UNFAIR COMPETITION', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 0, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''})"
            ]
          },
          "execution_count": 371,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a FAISS VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "####❓ Question #1:\n",
        "\n",
        "List out a few of the techniques that FAISS uses that make it performant.\n",
        "\n",
        "**Answer** FAISS is very flexible in terms of retrieval options. The default options seem to be Euclidean distance, dot product and cosine similarity (which is essentially a dot product on normalized vectors). However, FAISS also supports alternative retrieval options that offer various levels of compromise between memory, search speed and accuracy. Its GPU implementation significantly accelerates search operations, supporting native multi-GPU configurations. FAISS efficiently handles billions of vectors, crucial for large-scale datasets common in AI applications.\n",
        "\n",
        "> NOTE: Check the [repository](https://github.com/facebookresearch/faiss) for more information about FAISS!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"Who is the plantiff?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "34526432-09f0-4445-93d3-f966f25dd6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='would be owned by the foundation and used ‘for the good of the world’[.]” Plaintiff \\nreplied: “Agree on all.” Ex. 2 at 1.' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 27, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='property and derivative works funded by those monies, Plaintiff is presently unable to ascertain his \\ninterest in or the use, allocation, or distribution of assets without an accounting. Plaintiff is therefore \\nentitled to an accounting.' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 32, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 35 – \\nCOMPLAINT \\n \\nDEMAND FOR JURY TRIAL \\nPlaintiff hereby demands trial by jury as to all issues, claims, and/or causes of action properly \\ntriable before a jury \\n \\nDATED: February 29, 2024 \\nIRELL & MANELLA LLP \\n \\n \\nBy:                                                                 \\nMorgan Chu \\nAlan Heinrich \\nIian Jablon \\nAbigail Sellers \\nJustin Koo \\nHenry White \\n \\nAttorneys for Plaintiff Elon Musk' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 34, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n",
            "page_content='Exhibit 1' metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 35, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "eRCq_OKUQbKk"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "fa6d986a-f252-409e-990c-7f2eb077a1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MgAa9JwBuJx"
      },
      "source": [
        "####🏗️ Activity #1:\n",
        "\n",
        "Describe the pipeline shown above in simple terms. You can include a diagram if desired.\n",
        "\n",
        "**Answer**: Above we have a RAG chain that first uses Python's itemgetter to extract the \"question\" from input, passing it to a retriever but also keeping the original \"question\" intact. A RunnablePassthrough then temporarily holds the \"context\" (which is obtained as an output of the \"question\" chained into the retriever) without altering it. Finally, the \"context\" and \"question\" are used as inputs for a prompt for ChatOpenAI, generating a \"response\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "6d926d73-0b0a-40b4-b4b2-48250f97f0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elon Musk\n"
          ]
        }
      ],
      "source": [
        "question = \"Who is the plantiff?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "38418031-7020-4c70-d695-48400e966c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The complaint pertains to breach of fiduciary duty, unfair business practices, accounting, and a demand for a jury trial.\n",
            "[Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 31 – \\nCOMPLAINT \\n \\nTHIRD CAUSE OF ACTION \\nBreach of Fiduciary Duty  \\nAgainst All Defendants \\n133. \\nPlaintiff realleges and incorporates by reference only paragraphs of this Complaint \\nnecessary for his claim of Breach of Fiduciary Duty. \\n134. \\nUnder California law, Defendants owe fiduciary duties to Plaintiff, including a duty \\nto use Plaintiff’s contributions for the purposes for which they were made. E.g., Cal. Bus. & Prof. \\nCode § 17510.8. Defendants have repeatedly breached their fiduciary duties to Plaintiff, including \\nby:', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 30, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 33 – \\nCOMPLAINT \\n \\nand by those acting in concert with them arising from these acts of unfair competition and other \\nunfair business practices.  \\n144. \\nPlaintiff is entitled to restitution and/or disgorgement of any and all monies received \\nby Defendants while they engaged in such practices, in addition to prejudgment interest pursuant to \\nBusiness & Professions Code § 17200 et seq. Plaintiff further seeks to enjoin Defendants from \\ncarrying out such activities again in the future, and an order compelling specific performance.   \\nFIFTH CAUSE OF ACTION \\nAccounting', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 32, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 35 – \\nCOMPLAINT \\n \\nDEMAND FOR JURY TRIAL \\nPlaintiff hereby demands trial by jury as to all issues, claims, and/or causes of action properly \\ntriable before a jury \\n \\nDATED: February 29, 2024 \\nIRELL & MANELLA LLP \\n \\n \\nBy:                                                                 \\nMorgan Chu \\nAlan Heinrich \\nIian Jablon \\nAbigail Sellers \\nJustin Koo \\nHenry White \\n \\nAttorneys for Plaintiff Elon Musk', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 34, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}), Document(page_content='obligations as a remedy for Defendants’ breaches of fiduciary duty. \\nFOURTH CAUSE OF ACTION \\nUnfair Business Practices - Cal. Bus. & Prof. Code §§ 17200 et seq. \\nAgainst All Defendants \\n137. \\nPlaintiff realleges and incorporates by reference only paragraphs of this Complaint \\nnecessary for his claim of Unfair Business Practices. \\n138. \\nCalifornia Business and Professions Code sections 17200 et seq. provides that any \\nperson or entity that engages, has engaged, or proposes to engage in unfair business practices may \\nbe enjoined. \\n139. \\nDefendants have engaged in unfair competition and other unfair business practices', metadata={'source': 'DataRepository/MuskComplaint.pdf', 'file_path': 'DataRepository/MuskComplaint.pdf', 'page': 31, 'total_pages': 46, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''})]\n"
          ]
        }
      ],
      "source": [
        "question = \"What does this complaint pertain to?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# 🤝 Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 1: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evluating on every core metric today, but in order to do that - we'll need to creat a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!\n",
        "\n",
        "> NOTE: This process will use `gpt-3.5-turbo-16k` as the base generator and `gpt-4` as the critic - if you're attempting to create a lot of samples please be aware of cost, as well as rate limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"DataRepository/MuskComplaint.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 400\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "####❓ Question #2:\n",
        "\n",
        "Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "\n",
        "**Answer**:  Because we want to test whether the system can handle unseen data and diverse scenarios effectively, not just the specific conditions it was trained or optimized on. A different strategy might reveal strengths or weaknesses that were not apparent under the training conditions, providing a better understanding of the system's performance and areas for improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "0942c5d1-d151-44af-ad1f-c1373ef3e634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "execution_count": 384,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 385,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents == eval_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8b4c1aafe67048798cdadd46207b4b84",
            "83e3f8bf55454600b299fe63b608852a",
            "4818628434aa4a0e8d7826f152c0da99",
            "c3e047dfd4ec4a859e0274a54ace1432",
            "1b3b9e3adf85473a81055265d9a5b89f",
            "2a4b2b14a02b46c1ac67fc1581133523",
            "decd5f4c69a845cc8fad4c21524c2fd9",
            "e44a47a5a2184c2780ac27e16ace0f7f",
            "317a7d84efc74420abea8e311137f272",
            "611021c94b8a42c58897925acb8b3c5e",
            "ba72a1f57074488da5e34f8d02e748f8",
            "6de6fb8ef2974573b50bad678620f2d1",
            "09ce5c2f37fb469683ed7cf3bd7566f6",
            "58d7c8b4640249df89b60e9eef4d2328",
            "394fb069eb3c4269bb3c970cc04369a9",
            "2235baa0358a4b8cad60508d5d1d8380",
            "570a1f9809e143ef8d858e1c5dc9837d",
            "42c4905b54d8482588d57485c563ee78",
            "26ee70b94d75449cbe7b7ce40ebc1049",
            "bc3b3593ad1e4c5bad6057a3d3872bb4",
            "c5651973a0534d3da51d0a18b13deff3",
            "8745b8f8f8ec46869c66758c4bc6b2e0"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "b97b381f-ecd0-441d-924d-09e6d2187954"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ec88a3a37d048baa570379fb30a15a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding nodes:   0%|          | 0/188 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filename and doc_id are the same for all nodes.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b30a42fc18104538a09fa0d69cdb345a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "\n",
        "generator = TestsetGenerator.with_openai()\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, test_size=12, distributions={simple: 0.25, reasoning: 0.25, multi_context: 0.5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIGT0XLz8ze"
      },
      "source": [
        "####❓ Question #3:\n",
        "\n",
        "`{simple: 0.5, reasoning: 0.25, multi_context: 0.25}`\n",
        "\n",
        "What exactly does this mapping refer to?\n",
        "\n",
        "**Answer** RAGAS provides a synthetic Q&A data genaration module that can cover different levels of complexity. First, 'simple' questions are generated where seeding is used to ensure diversity. Then, the original questions might undergo \"evolutions\", whereby they become more convolved. The new questions might require reasoning in order to be answered ('reasoning' questions), or might require information contained in multiple chunks ('multi_context' questions). This is a way to simulate the variability in queries that production RAG systems might receive. \n",
        "\n",
        "> NOTE: Check out the Ragas documentation on this generation process [here](https://docs.ragas.io/en/stable/concepts/testset_generation.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "a8e95364-f3e4-4f20-da3d-05f6f971afdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='What did Mr. Altman suggest as a means to ensure AI is created safely?', contexts=['1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\n12 \\n13 \\n14 \\n15 \\n16 \\n17 \\n18 \\n19 \\n20 \\n21 \\n22 \\n23 \\n24 \\n25 \\n26 \\n27 \\n28 \\n \\n \\n– 11 – \\nCOMPLAINT \\n \\n43. \\nMr. Altman appeared to share Mr. Musk’s concerns surrounding AI. In public blog \\nposts dating back to 2014, Mr. Altman stated that AGI, if made, would “be the biggest development \\nin technology ever.” Mr. Altman pointed out that there are many companies making strides towards \\nachieving AGI, but acknowledged the unfortunate reality that the “good ones are very secretive \\nabout it.” \\n44. \\nOn February 25, 2015, Mr. Altman also expressed his concern surrounding the \\ndevelopment of what he referred to as “superhuman machine intelligence” which he identified as \\n“probably the greatest threat to the continued existence of humanity” and emphasized that “as a \\nhuman programmed to survive and reproduce, I feel we should fight it.” Further, Mr. Altman \\ncriticized those who believed that “superhuman machine intelligence” was dangerous but dismissed \\nit as “never going to happen or definitely very far off.” He accused them of engaging in “sloppy, \\ndangerous thinking.” \\n45. \\nIndeed, in early March 2015, Mr. Altman extolled the importance of government \\nregulation as a means to ensure AI is created safely and suggested that “a group of very smart people \\nwith a lot of resources” likely involving “US companies in some way” would be the most probable \\ngroup to achieve “superhuman machine intelligence” first. \\n46.'], ground_truth='Mr. Altman suggested government regulation as a means to ensure AI is created safely.', evolution_type='simple')"
            ]
          },
          "execution_count": 387,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "test_df = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "92554c28-97b0-44b5-c356-05367d764ad8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What did Mr. Altman suggest as a means to ensu...</td>\n",
              "      <td>[1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...</td>\n",
              "      <td>Mr. Altman suggested government regulation as ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How did researchers at the University of Tokyo...</td>\n",
              "      <td>[implementation for others to build on. \\n84. ...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What strategy video game did OpenAI compete in?</td>\n",
              "      <td>[multiple members including OpenAI, Inc., Aest...</td>\n",
              "      <td>OpenAI competed in Dota 2, a strategy video game.</td>\n",
              "      <td>simple</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How did the Board restructuring affect OpenAI'...</td>\n",
              "      <td>[the Board from which it could keep a close ey...</td>\n",
              "      <td>The Board restructuring affected OpenAI's chec...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does Mr. Nadella say about Microsoft's st...</td>\n",
              "      <td>[Indeed, during an interview shortly after Mr....</td>\n",
              "      <td>Mr. Nadella states that if OpenAI disappeared,...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Which organization used DeepMind's influence t...</td>\n",
              "      <td>[multiple members including OpenAI, Inc., Aest...</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does GPT-4's reasoning compare to humans o...</td>\n",
              "      <td>[dramatically compressing. \\n86. \\nOn March 14...</td>\n",
              "      <td>GPT-4's reasoning is better than average human...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What was OpenAI's original intention in the AG...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>OpenAI's original intention in the AGI race, a...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the ownership and control relationship...</td>\n",
              "      <td>[multiple members including OpenAI, Inc., Aest...</td>\n",
              "      <td>OpenAI, Inc. manages OpenAI Global, LLC.</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What is Artificial General Intelligence (AGI)...</td>\n",
              "      <td>[food is shown in a photo. One of the hallmark...</td>\n",
              "      <td>The basic concept of AGI is a general purpose ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What benefits do investors gain from OpenAI's ...</td>\n",
              "      <td>[not be the first Court to hold otherwise. \\n1...</td>\n",
              "      <td>nan</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"What is the role of open-source development i...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>The role of open-source development in advanci...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What did Mr. Altman suggest as a means to ensu...   \n",
              "1   How did researchers at the University of Tokyo...   \n",
              "2     What strategy video game did OpenAI compete in?   \n",
              "3   How did the Board restructuring affect OpenAI'...   \n",
              "4   What does Mr. Nadella say about Microsoft's st...   \n",
              "5   Which organization used DeepMind's influence t...   \n",
              "6   How does GPT-4's reasoning compare to humans o...   \n",
              "7   What was OpenAI's original intention in the AG...   \n",
              "8   What is the ownership and control relationship...   \n",
              "9   \"What is Artificial General Intelligence (AGI)...   \n",
              "10  What benefits do investors gain from OpenAI's ...   \n",
              "11  \"What is the role of open-source development i...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [1 \\n2 \\n3 \\n4 \\n5 \\n6 \\n7 \\n8 \\n9 \\n10 \\n11 \\...   \n",
              "1   [implementation for others to build on. \\n84. ...   \n",
              "2   [multiple members including OpenAI, Inc., Aest...   \n",
              "3   [the Board from which it could keep a close ey...   \n",
              "4   [Indeed, during an interview shortly after Mr....   \n",
              "5   [multiple members including OpenAI, Inc., Aest...   \n",
              "6   [dramatically compressing. \\n86. \\nOn March 14...   \n",
              "7   [profit developing AGI for the benefit of huma...   \n",
              "8   [multiple members including OpenAI, Inc., Aest...   \n",
              "9   [food is shown in a photo. One of the hallmark...   \n",
              "10  [not be the first Court to hold otherwise. \\n1...   \n",
              "11  [profit developing AGI for the benefit of huma...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   Mr. Altman suggested government regulation as ...         simple   \n",
              "1   Researchers at the University of Tokyo and Goo...         simple   \n",
              "2   OpenAI competed in Dota 2, a strategy video game.         simple   \n",
              "3   The Board restructuring affected OpenAI's chec...      reasoning   \n",
              "4   Mr. Nadella states that if OpenAI disappeared,...      reasoning   \n",
              "5                                              OpenAI      reasoning   \n",
              "6   GPT-4's reasoning is better than average human...  multi_context   \n",
              "7   OpenAI's original intention in the AGI race, a...  multi_context   \n",
              "8            OpenAI, Inc. manages OpenAI Global, LLC.  multi_context   \n",
              "9   The basic concept of AGI is a general purpose ...  multi_context   \n",
              "10                                                nan  multi_context   \n",
              "11  The role of open-source development in advanci...  multi_context   \n",
              "\n",
              "    episode_done  \n",
              "0           True  \n",
              "1           True  \n",
              "2           True  \n",
              "3           True  \n",
              "4           True  \n",
              "5           True  \n",
              "6           True  \n",
              "7           True  \n",
              "8           True  \n",
              "9           True  \n",
              "10          True  \n",
              "11          True  "
            ]
          },
          "execution_count": 389,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "9e14b904-7d52-4dec-f65e-e6d13c3e9e79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What did Mr. Altman suggest as a means to ensure AI is created safely?',\n",
              " 'answer': 'Government regulation.',\n",
              " 'contexts': ['“probably the greatest threat to the continued existence of humanity” and emphasized that “as a \\nhuman programmed to survive and reproduce, I feel we should fight it.” Further, Mr. Altman \\ncriticized those who believed that “superhuman machine intelligence” was dangerous but dismissed \\nit as “never going to happen or definitely very far off.” He accused them of engaging in “sloppy, \\ndangerous thinking.” \\n45. \\nIndeed, in early March 2015, Mr. Altman extolled the importance of government \\nregulation as a means to ensure AI is created safely and suggested that “a group of very smart people \\nwith a lot of resources” likely involving “US companies in some way” would be the most probable',\n",
              "  'to ensure that AI was developed and practiced safely. \\n40. \\nFollowing Google’s acquisition of DeepMind, Mr. Musk began “hosting his own \\nseries of dinner discussions on ways to counter Google and promote AI safety.” Mr. Musk also \\nreached out to President Barack Obama to discuss AI and AI safety. In 2015, Mr. Musk and \\nPresident Obama had a meeting during which Mr. Musk explained the dangers of AI and advocated \\nfor regulation. Mr. Musk felt that President Obama understood the dangers of AI, but regulation \\nnever came. \\n41. \\nDespite these setbacks, Mr. Musk continued to advocate for safe AI practices. In',\n",
              "  'calling for regulation of AI. Mr. Musk defended the idea of the regulation of AI to Mr. Hassabis, \\nstating: “If done well, it may very well accelerate AI in the long term. Without the public comfort \\nthat regulatory oversight provides, there could very well be a situation where an AI causes great \\nharm and thereafter AI research is banned as dangerous to public safety.” \\n48. \\nFive days after Mr. Hassabis reached out to Mr. Musk about the open letter regarding \\nAI, Mr. Hassabis announced the first meeting of the Google DeepMind AI Ethics Board, a board',\n",
              "  'such as: \\na. “The specific purpose of this corporation is to provide funding for research, \\ndevelopment and distribution of technology related to artificial intelligence. The \\nresulting technology will benefit the public and the corporation will seek to open \\nsource technology for the public benefit when applicable. The corporation is not \\norganized for the private gain of any person.” Ex. 1 at 1. \\nb. Mr. Altman stated: “The mission would be to create the first general AI and use it \\nfor individual empowerment—ie, the distributed version of the future that seems the \\nsafest. More generally, safety should be a first-class requirement. . . . The technology'],\n",
              " 'ground_truth': 'Mr. Altman suggested government regulation as a means to ensure AI is created safely.'}"
            ]
          },
          "execution_count": 393,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 2: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d46db515c4d543d898ef91d05df2d0da",
            "af19ef64986b435c8c118e882e26f6a9",
            "14d8c6593d6b41df8dfb290ab9f55ca1",
            "8531b3d7f1cd424f8d3fc2e6bcd875a0",
            "4e5db0ff4ff44577963dbcc651ea10b8",
            "9caba03e810f4407b78cb1c1b6b9be08",
            "2bf9a43c99cf4e05a0f376fde6af9ca6",
            "384a04784f9745088478d9372161c8ae",
            "c981e401946b4dfca65b18b6ae56bf33",
            "b319ac9b4f1b43d5a41d6f10e6e1c1c6",
            "002fc233bee54ea0a9729365f1e0f972"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "dffb177c-c7c6-421d-9fde-7988f960949e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2602ae8140884a87b3260f148012dce5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "71f706b1-b6c6-4eaa-cf75-efe719ed66d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'faithfulness': 0.9167, 'answer_relevancy': 0.9298, 'context_recall': 0.8194, 'context_precision': 0.8403, 'answer_correctness': 0.7327}\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "2acf7822-7029-4c0f-966a-4f7c5d47df1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What did Mr. Altman suggest as a means to ensu...</td>\n",
              "      <td>Government regulation.</td>\n",
              "      <td>[“probably the greatest threat to the continue...</td>\n",
              "      <td>Mr. Altman suggested government regulation as ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.890794</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.962540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How did researchers at the University of Tokyo...</td>\n",
              "      <td>By simply adding 'Let's think step by step' be...</td>\n",
              "      <td>[implementation for others to build on. \\n84. ...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908146</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.719096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What strategy video game did OpenAI compete in?</td>\n",
              "      <td>Dota 2</td>\n",
              "      <td>[77. \\nInitial work at OpenAI followed much in...</td>\n",
              "      <td>OpenAI competed in Dota 2, a strategy video game.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.953836</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.716374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How did the Board restructuring affect OpenAI'...</td>\n",
              "      <td>The Board restructuring collapsed OpenAI's cor...</td>\n",
              "      <td>[the Board from which it could keep a close ey...</td>\n",
              "      <td>The Board restructuring affected OpenAI's chec...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.916064</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.671755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does Mr. Nadella say about Microsoft's st...</td>\n",
              "      <td>Mr. Nadella stated that Microsoft was very con...</td>\n",
              "      <td>[Indeed, during an interview shortly after Mr....</td>\n",
              "      <td>Mr. Nadella states that if OpenAI disappeared,...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974927</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.736825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Which organization used DeepMind's influence t...</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>[a superhuman level of play in the games of ch...</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872235</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does GPT-4's reasoning compare to humans o...</td>\n",
              "      <td>GPT-4's reasoning is superior to humans on exa...</td>\n",
              "      <td>[titled “Sparks of Artificial General Intellig...</td>\n",
              "      <td>GPT-4's reasoning is better than average human...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.921261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.484975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What was OpenAI's original intention in the AG...</td>\n",
              "      <td>OpenAI's original intention in the AGI race as...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>OpenAI's original intention in the AGI race, a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.946791</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.748239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the ownership and control relationship...</td>\n",
              "      <td>OpenAI Global, LLC has two members: Microsoft ...</td>\n",
              "      <td>[LLC through its general partner, OpenAI GP, L...</td>\n",
              "      <td>OpenAI, Inc. manages OpenAI Global, LLC.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.896853</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.531793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What is Artificial General Intelligence (AGI)...</td>\n",
              "      <td>Artificial General Intelligence (AGI) is a gen...</td>\n",
              "      <td>[food is shown in a photo. One of the hallmark...</td>\n",
              "      <td>The basic concept of AGI is a general purpose ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.929179</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.539360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What benefits do investors gain from OpenAI's ...</td>\n",
              "      <td>Investors gain tax benefits and profit potenti...</td>\n",
              "      <td>[not be the first Court to hold otherwise. \\n1...</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.972196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.931058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"What is the role of open-source development i...</td>\n",
              "      <td>The role of open-source development in advanci...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>The role of open-source development in advanci...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974770</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.749954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What did Mr. Altman suggest as a means to ensu...   \n",
              "1   How did researchers at the University of Tokyo...   \n",
              "2     What strategy video game did OpenAI compete in?   \n",
              "3   How did the Board restructuring affect OpenAI'...   \n",
              "4   What does Mr. Nadella say about Microsoft's st...   \n",
              "5   Which organization used DeepMind's influence t...   \n",
              "6   How does GPT-4's reasoning compare to humans o...   \n",
              "7   What was OpenAI's original intention in the AG...   \n",
              "8   What is the ownership and control relationship...   \n",
              "9   \"What is Artificial General Intelligence (AGI)...   \n",
              "10  What benefits do investors gain from OpenAI's ...   \n",
              "11  \"What is the role of open-source development i...   \n",
              "\n",
              "                                               answer  \\\n",
              "0                              Government regulation.   \n",
              "1   By simply adding 'Let's think step by step' be...   \n",
              "2                                              Dota 2   \n",
              "3   The Board restructuring collapsed OpenAI's cor...   \n",
              "4   Mr. Nadella stated that Microsoft was very con...   \n",
              "5                                              OpenAI   \n",
              "6   GPT-4's reasoning is superior to humans on exa...   \n",
              "7   OpenAI's original intention in the AGI race as...   \n",
              "8   OpenAI Global, LLC has two members: Microsoft ...   \n",
              "9   Artificial General Intelligence (AGI) is a gen...   \n",
              "10  Investors gain tax benefits and profit potenti...   \n",
              "11  The role of open-source development in advanci...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [“probably the greatest threat to the continue...   \n",
              "1   [implementation for others to build on. \\n84. ...   \n",
              "2   [77. \\nInitial work at OpenAI followed much in...   \n",
              "3   [the Board from which it could keep a close ey...   \n",
              "4   [Indeed, during an interview shortly after Mr....   \n",
              "5   [a superhuman level of play in the games of ch...   \n",
              "6   [titled “Sparks of Artificial General Intellig...   \n",
              "7   [profit developing AGI for the benefit of huma...   \n",
              "8   [LLC through its general partner, OpenAI GP, L...   \n",
              "9   [food is shown in a photo. One of the hallmark...   \n",
              "10  [not be the first Court to hold otherwise. \\n1...   \n",
              "11  [profit developing AGI for the benefit of huma...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   Mr. Altman suggested government regulation as ...           1.0   \n",
              "1   Researchers at the University of Tokyo and Goo...           1.0   \n",
              "2   OpenAI competed in Dota 2, a strategy video game.           1.0   \n",
              "3   The Board restructuring affected OpenAI's chec...           1.0   \n",
              "4   Mr. Nadella states that if OpenAI disappeared,...           1.0   \n",
              "5                                              OpenAI           0.0   \n",
              "6   GPT-4's reasoning is better than average human...           1.0   \n",
              "7   OpenAI's original intention in the AGI race, a...           1.0   \n",
              "8            OpenAI, Inc. manages OpenAI Global, LLC.           1.0   \n",
              "9   The basic concept of AGI is a general purpose ...           1.0   \n",
              "10                                                nan           1.0   \n",
              "11  The role of open-source development in advanci...           1.0   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.890794        1.000000           0.750000            0.962540  \n",
              "1           0.908146        1.000000           1.000000            0.719096  \n",
              "2           0.953836        1.000000           1.000000            0.716374  \n",
              "3           0.916064        1.000000           1.000000            0.671755  \n",
              "4           0.974927        1.000000           1.000000            0.736825  \n",
              "5           0.872235        0.333333           0.583333            1.000000  \n",
              "6           0.921261        1.000000           1.000000            0.484975  \n",
              "7           0.946791        1.000000           1.000000            0.748239  \n",
              "8           0.896853        1.000000           1.000000            0.531793  \n",
              "9           0.929179        0.500000           0.750000            0.539360  \n",
              "10          0.972196        0.000000           0.000000            0.931058  \n",
              "11          0.974770        1.000000           1.000000            0.749954  "
            ]
          },
          "execution_count": 397,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfiu_pLh3JL"
      },
      "source": [
        "## Task 3: Making Adjustments to our RAG Pipeline\n",
        "\n",
        "Now that we have established a baseline - we can see how any changes impact our pipeline's performance!\n",
        "\n",
        "Let's modify our retriever and see how that impacts our Ragas metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "nKIuM336isBL"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MultiQueryRetriever\n",
        "\n",
        "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rcj3L-i_c8"
      },
      "source": [
        "We'll also re-create our RAG pipeline using the abstractions that come packaged with LangChain v0.1.0!\n",
        "\n",
        "First, let's create a chain to \"stuff\" our documents into our context!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "EfdCgTw7jC4i"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYl5WdPnvLu"
      },
      "source": [
        "Next, we'll create the retrieval chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "9AK7wHVnn0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "id": "cmKORMfMoCjL"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Who is the plantiff?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICMsUWbWoOpf",
        "outputId": "04fb324e-682f-48cc-b369-a78d6396af88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The plaintiff is Elon Musk.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "id": "5s8ZGasYoVi6"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"What does this complaint pertain to?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNCdW4hoYT8",
        "outputId": "92d13a09-9e69-48af-fac2-1919123a980c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The complaint pertains to a legal case involving Plaintiff Elon Musk alleging breach of fiduciary duty, unfair business practices, and seeking an accounting, restitution, disgorgement of funds, and injunctive relief against all Defendants. The complaint also includes a demand for a jury trial.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxkU0HdpoaiE"
      },
      "source": [
        "Well, just from those responses this chain *feels* better - but lets see how it performs on our eval!\n",
        "\n",
        "Let's do the same process we did before to collect our pipeline's contexts and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {
        "id": "kO8cWxn2oinT"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgagfhPUtM2j"
      },
      "source": [
        "Now we can convert this into a dataset, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {
        "id": "5FcllGeSovP8"
      },
      "outputs": [],
      "source": [
        "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELYabwktR2C"
      },
      "source": [
        "Let's evaluate on the same metrics we did for the first pipeline and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "50599aa481d8460aa6655330b2b0fae3",
            "cfc93618fc084608bb413667fee91ea8",
            "3e85b387328f4df7b45dccbe6572b9bd",
            "cc50e0150a9947579a919757b85f38c9",
            "c03d5f58d31747d3a344f813755480fc",
            "17fde9c2236b4b1b9990dd2a9fbd58ff",
            "ddbe87e735534504b735211253c4b4d2",
            "2189fea4b75749d7bac330e613c31974",
            "d7148bed10a245509672dc60be6edd47",
            "3367eaf060c845648cda48963481ecb4",
            "4fc8cf791b1344809fe8c7ee9598a20a"
          ]
        },
        "id": "d7uHseWJo2TU",
        "outputId": "a0cf86d6-5b8e-4829-b660-b2c247202811"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27fe664b769a48a889c4b9ba25d1cb57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "JsFd0uDd2n5E",
        "outputId": "56ec498b-2100-4b79-db2a-30deb4ffddd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What did Mr. Altman suggest as a means to ensu...</td>\n",
              "      <td>Mr. Altman suggested that government regulatio...</td>\n",
              "      <td>[“probably the greatest threat to the continue...</td>\n",
              "      <td>Mr. Altman suggested government regulation as ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974245</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How did researchers at the University of Tokyo...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>[implementation for others to build on. \\n84. ...</td>\n",
              "      <td>Researchers at the University of Tokyo and Goo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.986865</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What strategy video game did OpenAI compete in?</td>\n",
              "      <td>OpenAI competed in Dota 2, a strategy video ga...</td>\n",
              "      <td>[77. \\nInitial work at OpenAI followed much in...</td>\n",
              "      <td>OpenAI competed in Dota 2, a strategy video game.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How did the Board restructuring affect OpenAI'...</td>\n",
              "      <td>The restructuring of the Board at OpenAI, Inc....</td>\n",
              "      <td>[the Board from which it could keep a close ey...</td>\n",
              "      <td>The Board restructuring affected OpenAI's chec...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.886073</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.842188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What does Mr. Nadella say about Microsoft's st...</td>\n",
              "      <td>Mr. Nadella stated that Microsoft was very con...</td>\n",
              "      <td>[Indeed, during an interview shortly after Mr....</td>\n",
              "      <td>Mr. Nadella states that if OpenAI disappeared,...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974927</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.841375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Which organization used DeepMind's influence t...</td>\n",
              "      <td>OpenAI used DeepMind's influence to compete in...</td>\n",
              "      <td>[77. \\nInitial work at OpenAI followed much in...</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.901718</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.718147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does GPT-4's reasoning compare to humans o...</td>\n",
              "      <td>GPT-4's reasoning capabilities were found to b...</td>\n",
              "      <td>[titled “Sparks of Artificial General Intellig...</td>\n",
              "      <td>GPT-4's reasoning is better than average human...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.921381</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.915019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What was OpenAI's original intention in the AG...</td>\n",
              "      <td>OpenAI's original intention, as per the Foundi...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>OpenAI's original intention in the AGI race, a...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.926395</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.541145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the ownership and control relationship...</td>\n",
              "      <td>OpenAI Global, LLC has two members: Microsoft ...</td>\n",
              "      <td>[LLC through its general partner, OpenAI GP, L...</td>\n",
              "      <td>OpenAI, Inc. manages OpenAI Global, LLC.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.896853</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.446089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"What is Artificial General Intelligence (AGI)...</td>\n",
              "      <td>Artificial General Intelligence (AGI) refers t...</td>\n",
              "      <td>[food is shown in a photo. One of the hallmark...</td>\n",
              "      <td>The basic concept of AGI is a general purpose ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.929179</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.798882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What benefits do investors gain from OpenAI's ...</td>\n",
              "      <td>Investors in OpenAI's new business model gain ...</td>\n",
              "      <td>[not be the first Court to hold otherwise. \\n1...</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.961853</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"What is the role of open-source development i...</td>\n",
              "      <td>The role of open-source development in advanci...</td>\n",
              "      <td>[profit developing AGI for the benefit of huma...</td>\n",
              "      <td>The role of open-source development in advanci...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.963632</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.885589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What did Mr. Altman suggest as a means to ensu...   \n",
              "1   How did researchers at the University of Tokyo...   \n",
              "2     What strategy video game did OpenAI compete in?   \n",
              "3   How did the Board restructuring affect OpenAI'...   \n",
              "4   What does Mr. Nadella say about Microsoft's st...   \n",
              "5   Which organization used DeepMind's influence t...   \n",
              "6   How does GPT-4's reasoning compare to humans o...   \n",
              "7   What was OpenAI's original intention in the AG...   \n",
              "8   What is the ownership and control relationship...   \n",
              "9   \"What is Artificial General Intelligence (AGI)...   \n",
              "10  What benefits do investors gain from OpenAI's ...   \n",
              "11  \"What is the role of open-source development i...   \n",
              "\n",
              "                                               answer  \\\n",
              "0   Mr. Altman suggested that government regulatio...   \n",
              "1   Researchers at the University of Tokyo and Goo...   \n",
              "2   OpenAI competed in Dota 2, a strategy video ga...   \n",
              "3   The restructuring of the Board at OpenAI, Inc....   \n",
              "4   Mr. Nadella stated that Microsoft was very con...   \n",
              "5   OpenAI used DeepMind's influence to compete in...   \n",
              "6   GPT-4's reasoning capabilities were found to b...   \n",
              "7   OpenAI's original intention, as per the Foundi...   \n",
              "8   OpenAI Global, LLC has two members: Microsoft ...   \n",
              "9   Artificial General Intelligence (AGI) refers t...   \n",
              "10  Investors in OpenAI's new business model gain ...   \n",
              "11  The role of open-source development in advanci...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [“probably the greatest threat to the continue...   \n",
              "1   [implementation for others to build on. \\n84. ...   \n",
              "2   [77. \\nInitial work at OpenAI followed much in...   \n",
              "3   [the Board from which it could keep a close ey...   \n",
              "4   [Indeed, during an interview shortly after Mr....   \n",
              "5   [77. \\nInitial work at OpenAI followed much in...   \n",
              "6   [titled “Sparks of Artificial General Intellig...   \n",
              "7   [profit developing AGI for the benefit of huma...   \n",
              "8   [LLC through its general partner, OpenAI GP, L...   \n",
              "9   [food is shown in a photo. One of the hallmark...   \n",
              "10  [not be the first Court to hold otherwise. \\n1...   \n",
              "11  [profit developing AGI for the benefit of huma...   \n",
              "\n",
              "                                         ground_truth  faithfulness  \\\n",
              "0   Mr. Altman suggested government regulation as ...           1.0   \n",
              "1   Researchers at the University of Tokyo and Goo...           1.0   \n",
              "2   OpenAI competed in Dota 2, a strategy video game.           1.0   \n",
              "3   The Board restructuring affected OpenAI's chec...           1.0   \n",
              "4   Mr. Nadella states that if OpenAI disappeared,...           1.0   \n",
              "5                                              OpenAI           1.0   \n",
              "6   GPT-4's reasoning is better than average human...           0.8   \n",
              "7   OpenAI's original intention in the AGI race, a...           1.0   \n",
              "8            OpenAI, Inc. manages OpenAI Global, LLC.           1.0   \n",
              "9   The basic concept of AGI is a general purpose ...           NaN   \n",
              "10                                                nan           0.8   \n",
              "11  The role of open-source development in advanci...           NaN   \n",
              "\n",
              "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0           0.974245             1.0           1.000000            0.741462  \n",
              "1           0.986865             1.0           1.000000            0.999481  \n",
              "2           1.000000             1.0           1.000000            0.741034  \n",
              "3           0.886073             1.0           0.916667            0.842188  \n",
              "4           0.974927             1.0           1.000000            0.841375  \n",
              "5           0.901718             0.5           1.000000            0.718147  \n",
              "6           0.921381             1.0           1.000000            0.915019  \n",
              "7           0.926395             1.0           1.000000            0.541145  \n",
              "8           0.896853             1.0           0.916667            0.446089  \n",
              "9           0.929179             0.5           1.000000            0.798882  \n",
              "10          0.961853             0.0           0.000000            0.180921  \n",
              "11          0.963632             1.0           1.000000            0.885589  "
            ]
          },
          "execution_count": 408,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results_df = advanced_retrieval_results.to_pandas()\n",
        "advanced_retrieval_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hzqq5VtZ2a"
      },
      "source": [
        "## Task 4: Evaluating our Adjusted Pipeline Against Our Baseline\n",
        "\n",
        "Now we can compare our results and see what directional changes occured!\n",
        "\n",
        "Let's refresh with our initial metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWGRaF5qx3V",
        "outputId": "ee4195d5-f3a3-45df-dff9-5139c93f640f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9167, 'answer_relevancy': 0.9298, 'context_recall': 0.8194, 'context_precision': 0.8403, 'answer_correctness': 0.7327}"
            ]
          },
          "execution_count": 409,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFv_yAeotmFs"
      },
      "source": [
        "And see how our advanced retrieval modified our chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpV11dxJo7xa",
        "outputId": "9510b961-4481-40fc-b54e-3a2a8348ce8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9600, 'answer_relevancy': 0.9436, 'context_recall': 0.8333, 'context_precision': 0.9028, 'answer_correctness': 0.7209}"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62NYn3iAvTjM",
        "outputId": "2d6eb84d-131c-457c-f71e-881248a4b2b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.043333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.929754</td>\n",
              "      <td>0.943593</td>\n",
              "      <td>0.013839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.840278</td>\n",
              "      <td>0.902778</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.732664</td>\n",
              "      <td>0.720944</td>\n",
              "      <td>-0.011720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.916667                                    0.960000   \n",
              "1    answer_relevancy  0.929754                                    0.943593   \n",
              "2      context_recall  0.819444                                    0.833333   \n",
              "3   context_precision  0.840278                                    0.902778   \n",
              "4  answer_correctness  0.732664                                    0.720944   \n",
              "\n",
              "      Delta  \n",
              "0  0.043333  \n",
              "1  0.013839  \n",
              "2  0.013889  \n",
              "3  0.062500  \n",
              "4 -0.011720  "
            ]
          },
          "execution_count": 411,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task 5: Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "####🏗️ Activity #2:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "#Let us repeat the process by using \"text-embedding-3-small\" instead of \"text-embedding-ada-002\" as our embedding model:\n",
        "new_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "-JPe1_Jx6Rnw"
      },
      "outputs": [],
      "source": [
        "#Again, we store our documents alongside their new embeddings in an index:\n",
        "new_vector_store = FAISS.from_documents(documents, new_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "#And expose our vector_store as a retriever:\n",
        "new_retriever = new_vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "M6Tyc3ZY7Km2"
      },
      "outputs": [],
      "source": [
        "# As we did before with \"text-embedding-ada-002\", we will also consider the effect of an advanced retriever:\n",
        "new_advanced_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "## As we did before with \"text-embedding-ada-002\", we will also consider the effect of document stuffing:\n",
        "new_retrieval_chain = create_retrieval_chain(new_advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "86f36527c3df458aae2e54f329c643d7",
            "4aef094bb7764f4fb7917a53de5cb40a",
            "f549d2bd447649c8aac65b0abd25cf23",
            "f413d1bf4faa44edbe5d081b1d3eaff2",
            "db2d3fee6c91439faabbb891a9574392",
            "8f117fd4781949148b1533a38e29c9d6",
            "2ab3fc4aee0b456bb0a06f15de98dafd",
            "9abbc4a5bc11444185ae5ecacbfa102a",
            "f3cf4145eef74579a41f740d62d842c4",
            "21731645603f4144a74f604cf7c01021",
            "c42583faf1f3472b82394432c7623562"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "e918ff10-3631-4563-fdfb-fbab474ea87c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26a2ae1fc93f4f738b5246174ed79058",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_advanced_retrieval_results = evaluate(new_response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "de1bc7a3-0224-4b8a-95f8-7184fd623661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8750, 'answer_relevancy': 0.9443, 'context_recall': 0.9167, 'context_precision': 0.8805, 'answer_correctness': 0.6977}"
            ]
          },
          "execution_count": 438,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.043333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.929754</td>\n",
              "      <td>0.943593</td>\n",
              "      <td>0.013839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.840278</td>\n",
              "      <td>0.902778</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.732664</td>\n",
              "      <td>0.720944</td>\n",
              "      <td>-0.011720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.916667                                    0.960000   \n",
              "1    answer_relevancy  0.929754                                    0.943593   \n",
              "2      context_recall  0.819444                                    0.833333   \n",
              "3   context_precision  0.840278                                    0.902778   \n",
              "4  answer_correctness  0.732664                                    0.720944   \n",
              "\n",
              "      Delta  \n",
              "0  0.043333  \n",
              "1  0.013839  \n",
              "2  0.013889  \n",
              "3  0.062500  \n",
              "4 -0.011720  "
            ]
          },
          "execution_count": 439,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "9e89e7f1-13e9-436d-e80a-c5241e1b945a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>ADA</th>\n",
              "      <th>Text Embedding 3</th>\n",
              "      <th>Delta - TE3 -&gt; ADA</th>\n",
              "      <th>Delta - TE3 -&gt; Baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>-0.085000</td>\n",
              "      <td>-0.041667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.929754</td>\n",
              "      <td>0.943593</td>\n",
              "      <td>0.944336</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.014581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.097222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.840278</td>\n",
              "      <td>0.902778</td>\n",
              "      <td>0.880463</td>\n",
              "      <td>-0.022315</td>\n",
              "      <td>0.040185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.732664</td>\n",
              "      <td>0.720944</td>\n",
              "      <td>0.697707</td>\n",
              "      <td>-0.023238</td>\n",
              "      <td>-0.034957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline       ADA  Text Embedding 3  \\\n",
              "0        faithfulness  0.916667  0.960000          0.875000   \n",
              "1    answer_relevancy  0.929754  0.943593          0.944336   \n",
              "2      context_recall  0.819444  0.833333          0.916667   \n",
              "3   context_precision  0.840278  0.902778          0.880463   \n",
              "4  answer_correctness  0.732664  0.720944          0.697707   \n",
              "\n",
              "   Delta - TE3 -> ADA  Delta - TE3 -> Baseline  \n",
              "0           -0.085000                -0.041667  \n",
              "1            0.000742                 0.014581  \n",
              "2            0.083333                 0.097222  \n",
              "3           -0.022315                 0.040185  \n",
              "4           -0.023238                -0.034957  "
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_original = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(new_advanced_retrieval_results.items()), columns=['Metric', 'Text Embedding 3'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['Delta - TE3 -> ADA'] = df_merged['Text Embedding 3'] - df_merged['ADA']\n",
        "df_merged['Delta - TE3 -> Baseline'] = df_merged['Text Embedding 3'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "####❓ Question #4:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?\n",
        "\n",
        "**Answer** Based on the results we obtained, `text-embedding-3-small` does not appear to be significantly better than `ada`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOciJLABDBnA"
      },
      "source": [
        "## BONUS ACTIVITY: Showcase Multi-Context Perfomance Changes\n",
        "\n",
        "Now that we've looked at a number of different examples - showcase the difference on the multi-context *specific* questions that were synthetically generated.\n",
        "\n",
        "> NOTE: You have all the data you'll need already in the notebook if you made it to this step!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "MY8l2EksDH43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad222c7a4d9f4fafab91b50833daa895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 1.0000, 'answer_relevancy': 0.9410, 'context_recall': 0.7500, 'context_precision': 0.7917, 'answer_correctness': 0.7080}"
            ]
          },
          "execution_count": 441,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The quick way to do that would be realising that the 'multi_context' questions in our dataset correspond to rows 6 to 11, by inspecting test_df. \n",
        "# However, a rigorous solution would be methodically filtering the rows of test_df that have ['evolution_type']== 'multi_context':\n",
        "multi_test_df = test_df[test_df['evolution_type']== 'multi_context'] \n",
        "\n",
        "#Then proceeding with all the steps with this filtered data frame:\n",
        "multi_test_questions = multi_test_df[\"question\"].values.tolist()\n",
        "multi_test_groundtruths = multi_test_df[\"ground_truth\"].values.tolist()\n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "#We invoke our RAG pipeline to get answers and contexts:\n",
        "for question in multi_test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "multi_response_dataset = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "#Finally we get results for the metrics when only multi-context questions were used in the evaluation:\n",
        "multi_results = evaluate(multi_response_dataset, metrics)\n",
        "\n",
        "multi_results\n",
        "                                        \n",
        "                                        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08d180f510494be88fad380918ae9476",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9600, 'answer_relevancy': 0.9367, 'context_recall': 0.7500, 'context_precision': 0.8194, 'answer_correctness': 0.5457}"
            ]
          },
          "execution_count": 442,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We do the same procedure for the modified RAG with advanced retrieval and document stuffing: \n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in multi_test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "multi_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "\n",
        "multi_advanced_retrieval_results = evaluate(multi_response_dataset_advanced_retrieval, metrics)\n",
        "multi_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Finally we repeat the procedure considering the change of embeddings model from ADA to 3-small:\n",
        "\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in multi_test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[453], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m multi_new_response_dataset_advanced_retrieval \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m : multi_test_questions,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m : answers,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m\"\u001b[39m : contexts,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m : multi_test_groundtruths\n\u001b[1;32m      6\u001b[0m })\n\u001b[0;32m----> 8\u001b[0m multi_new_advanced_retrieval_results \u001b[38;5;241m=\u001b[39m evaluate(multi_new_response_dataset_advanced_retrieval, metrics)\n\u001b[1;32m      9\u001b[0m multi_new_advanced_retrieval_results\n",
            "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/evaluation.py:208\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[1;32m    205\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
            "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/ragas/executor.py:129\u001b[0m, in \u001b[0;36mExecutor.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m executor_job\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     executor_job\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
            "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "multi_new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : multi_test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : multi_test_groundtruths\n",
        "})\n",
        "\n",
        "multi_new_advanced_retrieval_results = evaluate(multi_new_response_dataset_advanced_retrieval, metrics)\n",
        "multi_new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Now all that is left is to build a table for comparison:\n",
        "\n",
        "df_baseline = pd.DataFrame(list(multi_results.items()), columns=['Metric', 'Baseline'])\n",
        "df_original = pd.DataFrame(list(multi_advanced_retrieval_results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(multi_new_advanced_retrieval_results.items()), columns=['Metric', 'Text Embedding 3'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['Delta - TE3 -> ADA'] = df_merged['Text Embedding 3'] - df_merged['ADA']\n",
        "df_merged['Delta - TE3 -> Baseline'] = df_merged['Text Embedding 3'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002fc233bee54ea0a9729365f1e0f972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09ce5c2f37fb469683ed7cf3bd7566f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570a1f9809e143ef8d858e1c5dc9837d",
            "placeholder": "​",
            "style": "IPY_MODEL_42c4905b54d8482588d57485c563ee78",
            "value": "Generating: 100%"
          }
        },
        "14d8c6593d6b41df8dfb290ab9f55ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_384a04784f9745088478d9372161c8ae",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c981e401946b4dfca65b18b6ae56bf33",
            "value": 50
          }
        },
        "17fde9c2236b4b1b9990dd2a9fbd58ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3b9e3adf85473a81055265d9a5b89f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "21731645603f4144a74f604cf7c01021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2189fea4b75749d7bac330e613c31974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2235baa0358a4b8cad60508d5d1d8380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ee70b94d75449cbe7b7ce40ebc1049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4b2b14a02b46c1ac67fc1581133523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab3fc4aee0b456bb0a06f15de98dafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf9a43c99cf4e05a0f376fde6af9ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317a7d84efc74420abea8e311137f272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3367eaf060c845648cda48963481ecb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384a04784f9745088478d9372161c8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394fb069eb3c4269bb3c970cc04369a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5651973a0534d3da51d0a18b13deff3",
            "placeholder": "​",
            "style": "IPY_MODEL_8745b8f8f8ec46869c66758c4bc6b2e0",
            "value": " 10/10 [00:40&lt;00:00,  6.80s/it]"
          }
        },
        "3e85b387328f4df7b45dccbe6572b9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2189fea4b75749d7bac330e613c31974",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7148bed10a245509672dc60be6edd47",
            "value": 50
          }
        },
        "42c4905b54d8482588d57485c563ee78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4818628434aa4a0e8d7826f152c0da99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44a47a5a2184c2780ac27e16ace0f7f",
            "max": 318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_317a7d84efc74420abea8e311137f272",
            "value": 318
          }
        },
        "4aef094bb7764f4fb7917a53de5cb40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f117fd4781949148b1533a38e29c9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab3fc4aee0b456bb0a06f15de98dafd",
            "value": "Evaluating: 100%"
          }
        },
        "4e5db0ff4ff44577963dbcc651ea10b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc8cf791b1344809fe8c7ee9598a20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50599aa481d8460aa6655330b2b0fae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfc93618fc084608bb413667fee91ea8",
              "IPY_MODEL_3e85b387328f4df7b45dccbe6572b9bd",
              "IPY_MODEL_cc50e0150a9947579a919757b85f38c9"
            ],
            "layout": "IPY_MODEL_c03d5f58d31747d3a344f813755480fc"
          }
        },
        "570a1f9809e143ef8d858e1c5dc9837d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d7c8b4640249df89b60e9eef4d2328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ee70b94d75449cbe7b7ce40ebc1049",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc3b3593ad1e4c5bad6057a3d3872bb4",
            "value": 10
          }
        },
        "611021c94b8a42c58897925acb8b3c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de6fb8ef2974573b50bad678620f2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09ce5c2f37fb469683ed7cf3bd7566f6",
              "IPY_MODEL_58d7c8b4640249df89b60e9eef4d2328",
              "IPY_MODEL_394fb069eb3c4269bb3c970cc04369a9"
            ],
            "layout": "IPY_MODEL_2235baa0358a4b8cad60508d5d1d8380"
          }
        },
        "83e3f8bf55454600b299fe63b608852a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a4b2b14a02b46c1ac67fc1581133523",
            "placeholder": "​",
            "style": "IPY_MODEL_decd5f4c69a845cc8fad4c21524c2fd9",
            "value": "embedding nodes: 100%"
          }
        },
        "8531b3d7f1cd424f8d3fc2e6bcd875a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b319ac9b4f1b43d5a41d6f10e6e1c1c6",
            "placeholder": "​",
            "style": "IPY_MODEL_002fc233bee54ea0a9729365f1e0f972",
            "value": " 50/50 [00:21&lt;00:00,  1.43it/s]"
          }
        },
        "86f36527c3df458aae2e54f329c643d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aef094bb7764f4fb7917a53de5cb40a",
              "IPY_MODEL_f549d2bd447649c8aac65b0abd25cf23",
              "IPY_MODEL_f413d1bf4faa44edbe5d081b1d3eaff2"
            ],
            "layout": "IPY_MODEL_db2d3fee6c91439faabbb891a9574392"
          }
        },
        "8745b8f8f8ec46869c66758c4bc6b2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4c1aafe67048798cdadd46207b4b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83e3f8bf55454600b299fe63b608852a",
              "IPY_MODEL_4818628434aa4a0e8d7826f152c0da99",
              "IPY_MODEL_c3e047dfd4ec4a859e0274a54ace1432"
            ],
            "layout": "IPY_MODEL_1b3b9e3adf85473a81055265d9a5b89f"
          }
        },
        "8f117fd4781949148b1533a38e29c9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9abbc4a5bc11444185ae5ecacbfa102a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9caba03e810f4407b78cb1c1b6b9be08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af19ef64986b435c8c118e882e26f6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9caba03e810f4407b78cb1c1b6b9be08",
            "placeholder": "​",
            "style": "IPY_MODEL_2bf9a43c99cf4e05a0f376fde6af9ca6",
            "value": "Evaluating: 100%"
          }
        },
        "b319ac9b4f1b43d5a41d6f10e6e1c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba72a1f57074488da5e34f8d02e748f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3b3593ad1e4c5bad6057a3d3872bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c03d5f58d31747d3a344f813755480fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e047dfd4ec4a859e0274a54ace1432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611021c94b8a42c58897925acb8b3c5e",
            "placeholder": "​",
            "style": "IPY_MODEL_ba72a1f57074488da5e34f8d02e748f8",
            "value": " 318/318 [00:30&lt;00:00,  1.69s/it]"
          }
        },
        "c42583faf1f3472b82394432c7623562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5651973a0534d3da51d0a18b13deff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c981e401946b4dfca65b18b6ae56bf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc50e0150a9947579a919757b85f38c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3367eaf060c845648cda48963481ecb4",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc8cf791b1344809fe8c7ee9598a20a",
            "value": " 50/50 [00:27&lt;00:00,  2.66it/s]"
          }
        },
        "cfc93618fc084608bb413667fee91ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fde9c2236b4b1b9990dd2a9fbd58ff",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbe87e735534504b735211253c4b4d2",
            "value": "Evaluating: 100%"
          }
        },
        "d46db515c4d543d898ef91d05df2d0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af19ef64986b435c8c118e882e26f6a9",
              "IPY_MODEL_14d8c6593d6b41df8dfb290ab9f55ca1",
              "IPY_MODEL_8531b3d7f1cd424f8d3fc2e6bcd875a0"
            ],
            "layout": "IPY_MODEL_4e5db0ff4ff44577963dbcc651ea10b8"
          }
        },
        "d7148bed10a245509672dc60be6edd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db2d3fee6c91439faabbb891a9574392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbe87e735534504b735211253c4b4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "decd5f4c69a845cc8fad4c21524c2fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e44a47a5a2184c2780ac27e16ace0f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3cf4145eef74579a41f740d62d842c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f413d1bf4faa44edbe5d081b1d3eaff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21731645603f4144a74f604cf7c01021",
            "placeholder": "​",
            "style": "IPY_MODEL_c42583faf1f3472b82394432c7623562",
            "value": " 50/50 [00:22&lt;00:00,  1.83it/s]"
          }
        },
        "f549d2bd447649c8aac65b0abd25cf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abbc4a5bc11444185ae5ecacbfa102a",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3cf4145eef74579a41f740d62d842c4",
            "value": 50
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
